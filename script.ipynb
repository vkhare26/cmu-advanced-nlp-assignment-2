{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Scraping web data using BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from bs4) (4.13.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from beautifulsoup4->bs4) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from beautifulsoup4->bs4) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install bs4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the Wikipedia page\n",
    "url = \"https://en.wikipedia.org/wiki/Pittsburgh\"\n",
    "url2=\"https://en.wikipedia.org/wiki/History_of_Pittsburgh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    html_content = response.text\n",
    "else:\n",
    "    print(\"Failed to retrieve the page\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the main content of the page; Wikipedia's content is inside <div id=\"bodyContent\"> or <div id=\"mw-content-text\">\n",
    "content_div = soup.find(\"div\", id=\"mw-content-text\")\n",
    "if content_div is None:\n",
    "    print(\"Could not find the main content!\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pittsburgh (/ˈpɪtsbɜːrɡ/ PITS-burg) is a city in and the county seat of Allegheny County, Pennsylvania, United States. It is the second-most populous city in Pennsylvania (after Philadelphia) and the 68th-most populous city in the U.S., with a population of 302,971 as of the 2020 census. The city is located in southwestern Pennsylvania at the confluence of the Allegheny River and Monongahela River, which combine to form the Ohio River.[7] It anchors the Pittsburgh metropolitan area, which had a population of 2.457 million residents and is the largest metro area in both the Ohio Valley and Appalachia, the second-largest in Pennsylvania, and the 26th-largest in the U.S. Pittsburgh is the principal city of the greater Pittsburgh–Weirton–Steubenville combined statistical area which includes parts of Ohio and West Virginia.\n",
      "Pittsburgh is known as \"the Steel City\" for its dominant role in the history of the U.S. steel industry.[8] It developed as a vital link of the Atlantic coast and Midwest, as the mineral-rich Allegheny Mountains led to the region being contested by the French and British empires, Virginians, Whiskey Rebels, and Civil War raiders.[9] For part of the 20th century, Pittsburgh was behind only New York City and Chicago in corporate headquarters employment; it had the most U.S. stockholders per capita.[10] Deindustrialization in the late 20th century resulted in massive layoffs among blue-collar workers as steel and other heavy industries declined, coinciding with several Pittsburgh-based corporations moving out of the city.[11] However, the city divested from steel and, since the 1990s, Pittsburgh has focused its energies on the healthcare, education, and technology industries.[12][13]\n",
      "Pittsburgh is home to large medical providers, including the University of Pittsburgh Medical Center and Allegheny Health Network, as well as 68 colleges and universities, including Carnegie Mellon University and the University of Pittsburgh.[14] The area has served as the federal agency headquarters for cyber defense, software engineering, robotics, energy research, and the nuclear navy.[15] The city is home to ten Fortune 500 companies and seven of the largest 300 U.S. law firms. Pittsburgh is sometimes called the \"City of Bridges\" for its 446 bridges.[8] Its rich industrial history left the area with renowned cultural institutions, including the Carnegie Museums of Pittsburgh, Pittsburgh Zoo & Aquarium, Phipps Conservatory and Botanical Gardens, the National Aviary, and a diverse cultural district.[16] The city's major league professional sports teams include the Pittsburgh Steelers, Pittsburgh Penguins, and Pittsburgh Pirates. Pittsburgh is additionally where Jehovah's Witnesses traces its earliest origins, and was the host of the 2009 G20 Pittsburgh summit.\n",
      "Pittsburgh was named in 1758, by Scottish General John Forbes, in honor of British statesman William Pitt, 1st Earl of Chatham. As Forbes was a Scotsman, he probably pronounced the name /ˈpɪtsbərə/ PITS-bər-ə (similar to Edinburgh).[17][18]\n",
      "Pittsburgh was incorporated as a borough on April 22, 1794, with the following Act:[19]\n",
      "\"Be it enacted by the Pennsylvania State Senate and Pennsylvania House of Representatives of the Commonwealth of Pennsylvania ... by the authority of the same, that the said town of Pittsburgh shall be ... erected into a borough, which shall be called the borough of Pittsburgh for ever.\"[20]\n",
      "From 1891 to 1911, the city's name was federally recognized as \"Pittsburg\", though use of the final h was retained during this period by the city government and other local organizations.[21][17] After a public campaign, the federal decision to drop the h was reversed.[17] The Pittsburg Press continued spelling the city without an h until 1921.[22]\n",
      "Kingdom of France 1690s–1763  Great Britain 1681–1781  United States 1776–present\n",
      "The area of the Ohio headwaters was long inhabited by the Shawnee and several other settled groups of Native Americans.[23] Shannopin's Town was an 18th-century Lenape (Delaware) town located roughly from where Penn Avenue is today, below the mouth of Two Mile Run, from 30th Street to 39th Street. According to George Croghan, the town was situated on the south bank of the Allegheny, nearly opposite what is now known as Washington's Landing, formerly Herr's Island, in what is now the Lawrenceville neighborhood.[24]: 289\n",
      "The first known European to enter the region was the French explorer Robert de La Salle from Quebec during his 1669 expedition down the Ohio River.[25][better source needed] European pioneers, primarily Dutch, followed in the early 18th century. Michael Bezallion was the first to describe the forks of the Ohio in a 1717 manuscript, and later that year European fur traders established area posts and settlements.[26]\n",
      "In 1749, French soldiers from Quebec launched an expedition to the forks to unite Canada with French Louisiana via the rivers.[26] During 1753–1754, the British hastily built Fort Prince George before a larger French force drove them off. The French built Fort Duquesne based on LaSalle's 1669 claims. The French and Indian War, the North American front of the Seven Years' War, began with the future Pittsburgh as its center. British General Edward Braddock was dispatched with Major George Washington as his aide to take Fort Duquesne.[27] The British and colonial force were defeated at Braddock's Field. General John Forbes finally took the forks in 1758. He began construction on Fort Pitt, named after William Pitt the Elder, while the settlement was named \"Pittsborough\".[28]\n",
      "During Pontiac's War, a loose confederation of Native American tribes laid siege to Fort Pitt in 1763; the siege was eventually lifted after Colonel Henry Bouquet defeated a portion of the besieging force at the Battle of Bushy Run. Bouquet strengthened the defenses of Fort Pitt the next year.[29][30][31][32]\n",
      "During this period, the powerful nations of the Iroquois Confederacy, based in New York, had maintained control of much of the Ohio Valley as hunting grounds by right of conquest after defeating other tribes. By the terms of the 1768 Treaty of Fort Stanwix, the Penns were allowed to purchase the modern region from the Iroquois. A 1769 survey referenced the future city as the \"Manor of Pittsburgh\".[33] Both the Colony of Virginia and the Province of Pennsylvania claimed the region under their colonial charters until 1780, when they agreed under a federal initiative to extend the Mason–Dixon line westward, placing Pittsburgh in Pennsylvania. On March 8, 1771, Bedford County, Pennsylvania was created to govern the frontier.\n",
      "On April 16, 1771, the city's first civilian local government was created as Pitt Township.[34][35] William Teagarden was the first constable, and William Troop was the first clerk.[36]\n",
      "Following the American Revolution, the village of Pittsburgh continued to grow. One of its earliest industries was boat building for settlers of the Ohio Country. In 1784, Thomas Vickroy completed a town plan which was approved by the Penn family attorney. Pittsburgh became a possession of Pennsylvania in 1785. The following year, the Pittsburgh Post-Gazette was started, and in 1787, the Pittsburgh Academy was chartered. Unrest during the Whiskey Rebellion of 1794 resulted in federal troops being sent to the area. By 1797, glass manufacture began, while the population grew to around 1,400. Settlers arrived after crossing the Appalachian Mountains or through the Great Lakes. Fort Pitt (now Pittsburgh) at the source of the Ohio River became the main base for settlers moving into the Northwest Territory.\n",
      "The federal government recognizes Pittsburgh as the starting point for the Lewis and Clark Expedition.[37] Preparations began in Pittsburgh in 1803 when Meriwether Lewis purchased a keelboat that would later be used to ascend the Missouri River.[38]\n",
      "The War of 1812 cut off the supply of British goods, stimulating American industry. By 1815, Pittsburgh was producing significant quantities of iron, brass, tin, and glass. On March 18, 1816, the 46-year-old local government became a city. It was served by numerous river steamboats that increased trading traffic on the rivers.\n",
      "In the 1830s, many Welsh people from the Merthyr steelworks immigrated to the city following the aftermath of the Merthyr Rising. By the 1840s, Pittsburgh was one of the largest cities west of the Allegheny Mountains. The Great Fire of Pittsburgh destroyed over a thousand buildings in 1845. The city rebuilt with the aid of Irish immigrants who came to escape the Great Famine. By 1857, Pittsburgh's 1,000 factories were consuming 22 million coal bushels yearly. Coal mining and iron manufacturing attracted waves of European immigrants to the area, with the most coming from Germany.\n",
      "Because Pennsylvania had been established as a free state after the Revolution, enslaved African Americans sought freedom here through escape as refugees from the South, or occasionally fleeing from travelers they were serving who stayed in the city. There were active stations of the Underground Railroad in the city, and numerous refugees were documented as getting help from station agents and African-American workers in city hotels. The Drennen Slave Girl walked out of the Monongahela House in 1850, apparently to freedom.[39] The Merchant's Hotel was also a place where African-American workers would advise slaves the state was free and aid them in getting to nearby stations of the Underground Railroad.[40] Sometimes refugee slaves from the South stayed in Pittsburgh, but other times they continued North, including into Canada. Many slaves left the city and county for Canada after Congress passed the 1850 Fugitive Slave Act, as it required cooperation from law enforcement even in free states and increased penalties. From 1850 to 1860, the black population in Allegheny County dropped from 3,431 to 2,725 as people headed to more safety in Canada.[39]\n",
      "The American Civil War boosted the city's economy with increased iron and armament demand by the Union. Andrew Carnegie began steel production in 1875 at the Edgar Thomson Steel Works in North Braddock, Pennsylvania, which evolved into the Carnegie Steel Company. He adopted the Bessemer process to increase production. Manufacturing was key to growth of Pittsburgh and the surrounding region. Railroad lines were built into the city along both rivers, increasing transportation access to important markets.\n",
      "In 1901, J. P. Morgan and attorney Elbert H. Gary merged Carnegie Steel Company and several other companies into U.S. Steel. By 1910, Pittsburgh was the nation's eighth-largest city, accounting for between one-third and one-half of national steel output.\n",
      "The Pittsburgh Agreement was subscribed in May 1918 between the Czech and Slovak nationalities, as envisioned by T. G. Masaryk, concerning the future foundation of Czechoslovakia.[42]\n",
      "The city suffered severe flooding in March 1936.\n",
      "The city's population swelled to more than a half million, attracting numerous European immigrants to its industrial jobs. By 1940, non-Hispanic whites were 90.6% of the city's population.[43] Pittsburgh also became a main destination of the African-American Great Migration from the rural South during the first half of the 20th century.[44] Limited initially by discrimination, some 95% percent of the men became unskilled steel workers.[45]\n",
      "During World War II, demand for steel increased and area mills operated 24 hours a day to produce 95 million tons of steel for the war effort.[28] This resulted in the highest levels of air pollution in the city's almost century of industry. The city's reputation as the \"arsenal of democracy\"[46][47] was being overshadowed by James Parton's 1868 observation of Pittsburgh being \"hell with the lid off.\"[48]\n",
      "Following World War II, the city launched a clean air and civic revitalization project known as the \"Renaissance,\" cleaning up the air and the rivers. The \"Renaissance II\" project followed in 1977, focused on cultural and neighborhood development. The industrial base continued to expand through the 1970s, but beginning in the early 1980s both the area's steel and electronics industries imploded during national industrial restructuring. There were massive layoffs from mill and plant closures.[11]\n",
      "In the later 20th century, the area shifted its economic base to education, tourism, and services, largely based on healthcare/medicine, finance, and high technology such as robotics. Although Pittsburgh successfully shifted its economy and remained viable, the city's population has never rebounded to its industrial-era highs. While 680,000 people lived in the city proper in 1950, a combination of suburbanization and economic turbulence resulted in a decrease in city population, even as the metropolitan area population increased again.\n",
      "During the late 2000s recession, Pittsburgh was economically strong, adding jobs when most cities were losing them. It was one of the few cities in the United States to see housing property values rise. Between 2006 and 2011, the Pittsburgh metropolitan statistical area (MSA) experienced over 10% appreciation in housing prices, the highest appreciation of the largest 25 metropolitan statistical areas in the United States, with 22 of the largest 25 metropolitan statistical areas experiencing depreciations in housing values.[49]\n",
      "In September 2009, the 2009 G20 Pittsburgh summit was held in Pittsburgh.[50]\n",
      "Pittsburgh has an area of 58.3 square miles (151 km2), of which 55.6 square miles (144 km2) is land and 2.8 square miles (7.3 km2), or 4.75%, is water. The 80th meridian west passes directly through the city's downtown.\n",
      "The city is located on the Allegheny Plateau, within the ecoregion of the Western Allegheny Plateau.[51] The Downtown area (also known as the Golden Triangle) sits where the Allegheny River flows from the northeast and the Monongahela River from the southeast to form the Ohio River. The convergence is at Point State Park and is referred to as \"the Point.\" The city extends east to include the Oakland and Shadyside sections, which are home to the University of Pittsburgh, Carnegie Mellon University, Chatham University, Carnegie Museum and Library, and many other educational, medical, and cultural institutions. The southern, western, and northern areas of the city are primarily residential.\n",
      "Many Pittsburgh neighborhoods are steeply sloped with two-lane roads. More than a quarter of neighborhood names make reference to \"hills,\" \"heights,\" or similar features.[a]\n",
      "The steps of Pittsburgh consist of 800 sets of outdoor public stairways with 44,645 treads and 24,090 vertical feet. They include hundreds of streets composed entirely of stairs, and many other steep streets with stairs for sidewalks.[52] Many provide vistas of the Pittsburgh area while attracting hikers and fitness walkers.[53]\n",
      "Bike and walking trails have been built to border many of the city's rivers and hollows. The Great Allegheny Passage and Chesapeake and Ohio Canal Towpath connect the city directly to downtown Washington, D.C. (some 335 miles [539 km] away) with a continuous bike/running trail.\n",
      "The city consists of the Downtown area, called the Golden Triangle,[54] and four main areas surrounding it—Central, North Side/North Hills, South Side/South Hills, East End, and West End. These areas are further divided into 90 neighborhoods.[55]\n",
      "Downtown Pittsburgh has 30 skyscrapers, nine over 500 feet (150 m), with the U.S. Steel Tower being the tallest at 841 ft (256 m).[56] The Cultural District spans 14 blocks along the Allegheny River and is home to theaters, arts venues, and a growing residential community. The Firstside portion of Downtown borders the Monongahela River, the historic Mon Wharf and hosts the distinctive PPG Place Gothic-style glass skyscraper complex. Downtown is served by the Port Authority's light rail system and multiple bridges leading north and south.[57] It is also home to Point Park University and Duquesne University which borders Uptown.\n",
      "The North Side, originally the independent Allegheny City until being annexed in 1907, is a primarily residential area with well-preserved 19th-century homes. It hosts attractions like Acrisure Stadium, PNC Park, the Andy Warhol Museum, and the National Aviary, among others.[58]\n",
      "The South Side, once home to railyards and mill workers, has seen revitalization with improvements to East Carson Street and new retail. It is now a vibrant neighborhood with diverse shopping and nightlife.[59] In the 1990s, the Urban Redevelopment Authority of Pittsburgh purchased the South Side Works steel mill property and redeveloped it into the SouthSide Works mixed-use development.\n",
      "The East End includes key institutions including the University of Pittsburgh, Carnegie Mellon University, Carnegie Museums of Art and Natural History, and Phipps Conservatory. It features many parks, including Mellon Park, Westinghouse Park, Schenley Park, Frick Park, The Frick Pittsburgh, Bakery Square, and the Pittsburgh Zoo, and vibrant neighborhoods like Shadyside. Squirrel Hill is also known as the hub of Jewish life in Pittsburgh, home to approximately 20 synagogues.[60] Oakland is home to several universities and the Petersen Events Center. The Strip District to the west along the Allegheny River is an open-air marketplace by day and a clubbing destination by night. Bloomfield is Pittsburgh's Little Italy and is known for its Italian restaurants and grocers. Lawrenceville is a revitalizing rowhouse neighborhood popular with artists and designers. The Hill District was home to photographer Charles Harris as well as various African-American jazz clubs.[61]\n",
      "The West End includes Mt. Washington, with its famous view of the downtown skyline, and numerous other residential neighborhoods such as Sheraden and Elliott.\n",
      "Pittsburgh falls within the borders of the Northeastern United States as defined by multiple US Government agencies. Pittsburgh is the principal city of the Pittsburgh Combined Statistical Area, a combined statistical area defined by the U.S. Census Bureau.\n",
      "Pittsburgh falls within the borders of Appalachia as defined by the Appalachian Regional Commission, and has long been characterized as the \"northern urban industrial anchor of Appalachia.\"[64] In its post-industrial state, Pittsburgh has been characterized as the \"Paris of Appalachia\",[65][66][67][68] recognizing the city's cultural, educational, healthcare, and technological resources, and is the largest city in Appalachia.\n",
      "Under the Köppen climate classification, Pittsburgh falls within either a hot-summer humid continental climate (Dfa) if the 0 °C (32 °F) isotherm is used or a humid subtropical climate (Cfa) if the −3 °C (27 °F) isotherm is used. Summers are hot and winters are moderately cold with wide variations in temperature. Despite this, it has one of the most pleasant summer climates between medium and large cities in the U.S.[69][70][71] The city lies in the USDA plant hardiness zone 6b except along the rivers where the zone is 7a.[72] The area has four distinct seasons: winters are cold and snowy, springs and falls are mild with moderate levels of sunshine, and summers are warm. As measured by percent possible sunshine, summer is by far the sunniest season, though annual sunshine is low among major US cities at well under 50%.[73]\n",
      "The warmest month of the year in Pittsburgh is July, with a 24-hour average of 73.2 °F (22.9 °C). Conditions are often humid, and combined with highs reaching 90 °F (32 °C) on an average 9.5 days a year,[74] a considerable heat index arises. The coolest month is January, when the 24-hour average is 28.8 °F (−1.8 °C), and lows of 0 °F (−18 °C) or below can be expected on an average 2.6 nights per year.[74] Officially, record temperatures range from −22 °F (−30 °C), on January 19, 1994 to 103 °F (39 °C), which occurred three times, most recently on July 16, 1988; the record cold daily maximum is −3 °F (−19 °C), which occurred three times, most recently the day of the all-time record low, while, conversely, the record warm daily minimum is 82 °F (28 °C) on July 1, 1901.[74][b] Due to elevation and location on the windward side of the Appalachian Mountains, 100 °F (38 °C)+ readings are very rare, and were last seen on July 15, 1995.[74]\n",
      "Average annual precipitation is 39.61 inches (1,006 mm) and precipitation is greatest in May while least in October; annual precipitation has historically ranged from 22.65 in (575 mm) in 1930 to 57.83 in (1,469 mm) in 2018.[75] On average, December and January have the greatest number of precipitation days. Snowfall averages 44.1 inches (112 cm) per season, but has historically ranged from 8.8 in (22 cm) in 1918–19 to 80 in (200 cm) in 1950–51.[76] There is an average of 59 clear days and 103 partly cloudy days per year, while 203 days are cloudy.[77] In terms of annual percent-average possible sunshine received, Pittsburgh (45%) is similar to Seattle (49%).\n",
      "The American Lung Association's 2024 \"State of the Air\" report, covering data from 2020 to 2022, indicated that while Pittsburgh's air quality is poor, it is improving. The city ranked 26th for short-term particle pollution, earning an F grade, and 19th for year-round particle pollution. It received a D grade for ozone pollution, ranking 50th for ozone smog.[81][82] However, United States Environmental Protection Agency (EPA) data from 2021 to 2024 shows that Pittsburgh's air quality was generally good or moderate.[83][84]\n",
      "Despite improvements, studies suggest Pittsburgh's air quality still impacts health. A 2014 to 2016 study found that children near pollution sources like industrial sites had asthma rates nearly three times the national average.[85] It also revealed that 38% of students lived in areas exceeding EPA's particle pollution standards, and 70% in areas surpassing the WHO's standards.[85] Most affected communities were minority populations, leading some residents to believe that the continuing effects of air pollution are a case of environmental racism.[86]\n",
      "As of 2005, Pittsburgh had 31,000 trees along 900 miles of streets. A 2011 analysis valued the annual benefits of the city's urban forest between $10 and $13 million, based on contributions to aesthetics, energy use, and air quality. The city invests $850,000 annually in tree planting and maintenance.[87]\n",
      "Local rivers in Pittsburgh continue to exceed EPA pollution limits, primarily due to frequently overflowing untreated sewage from the city's outdated infrastructure.[88] Pittsburgh's combined sewer system, built in the early 1900s, carries both stormwater and wastewater, with the treatment plant constructed in 1959.[89] Insufficient upgrades have led to public health concerns, as even a tenth of an inch of rain causes runoff to flow into rivers.[90][91] Nine billion gallons of untreated waste and stormwater flow into rivers, leading to health hazards and Clean Water Act violations.[92] The Allegheny County Sanitary Authority (ALCOSAN) is under a Consent Decree from the EPA and proposed a $2 billion system upgrade in 2017, approved by the EPA in 2019.[93][94][95]\n",
      "The Pittsburgh Water and Sewer Authority (PWSA), responsible for replacing pipes and setting water rates, has faced criticism for alleged mismanagement and for high lead levels in the city's drinking water, particularly in 2016.[96][97][98] While lead levels have risen for years, many residents blame PWSA's administrative changes for the spike.[99][100][101] In response, PWSA began adding orthophosphate to the water.[102] PWSA has also been working to replace lead pipes, and continuing to test water for lead.[102]\n",
      "There remains concern among residents over the long-term effects of this lead, particularly for children.[103] Some people also believe that the high levels of lead reflect environmental racism, as black and Hispanic children in Pittsburgh experience elevated blood-lead levels at 4 times the rate of white children.[103][104]\n",
      "At the 2010 census, there were 305,704 people residing in Pittsburgh, a decrease of 8.6% since 2000; 66.0% of the population was White, 25.8% Black or African American, 0.2% American Indian and Alaska Native, 4.4% Asian, 0.3% Other, and 2.3% mixed; in 2020, 2.3% of Pittsburgh's population was of Hispanic or Latino American origin of any race. Non-Hispanic whites were 64.8% of the population in 2010,[108] compared to 78.7% in 1970.[109] By the 2020 census, the population slightly declined further to 302,971.[107] Its racial and ethnic makeup in 2020 was 64.7% non-Hispanic white, 23.0% Black or African American, 5.8% Asian, and 3.2% Hispanic or Latino American of any race.\n",
      "Since the beginning of the 21st century, the five largest European ethnic groups in Pittsburgh were German (19.7%), Irish (15.8%), Italian (11.8%), Polish (8.4%), and English (4.6%), while the metropolitan area is approximately 22% German-American, 15.4% Italian American and 11.6% Irish American. Pittsburgh has one of the largest Italian-American communities in the nation,[115] and the fifth-largest Ukrainian community per the 1990 census.[116] Pittsburgh has one of the most extensive Croatian communities in the United States.[117] Overall, the Pittsburgh metro area has one of the largest populations of Slavic Americans in the country.\n",
      "Pittsburgh has a sizable Black and African American population, concentrated in various neighborhoods especially in the East End. There is also a small Asian community consisting of Indian immigrants, and a small Hispanic community consisting of Mexicans and Puerto Ricans.[118]\n",
      "In 2010, there were 143,739 households, out of which 21.9% had children under the age of 18 living with them, 31.2% were married couples living together, 16.5% had a female householder with no husband present, and 48.4% were non-families. 39.4% of all households were made up of individuals, and 13.7% had someone living alone who was 65 years of age or older. The average household size was 2.17 and the average family size was 2.95. In the city, the population was spread out, with 19.9% under the age of 18, 14.8% from 18 to 24, 28.6% from 25 to 44, 20.3% from 45 to 64, and 16.4% who were 65 years of age or older. The median age was 36 years. For every 100 females, there were 90.7 males. For every 100 females age 18 and over, there were 87.8 males.\n",
      "The median income for a household in the city was $28,588, and the median income for a family was $38,795. Males had a median income of $32,128 versus $25,500 for females. The per capita income for the city was $18,816. About 15.0% of families and 20.4% of the population were below the poverty line, including 27.5% of those under the age of 18 and 13.5% ages 65 or older. By the 2019 American Community Survey, the median income for a household increased to $53,799.[119] Families had a median income of $68,922; married-couple families had a median income of $93,500; and non-family households had a median income of $34,448. Pittsburgh's wealthiest suburbs within city limits are Squirrel Hill and Point Breeze, the only two areas of the city which have average household incomes over $100,000 a year.[120][121]\n",
      "As of 2018, much of Pittsburgh's population density was concentrated in the central, southern, and eastern areas. The city limits itself have a population density of 5,513 people per square mile; its most densely populated parts are North Oakland (at 21,200 per square mile) and Uptown Pittsburgh (at 19,869 per square mile). Outside of the city limits, Dormont and Mount Oliver are Pittsburgh's most densely-populated neighborhoods, with 11,167 and 9,902 people per square mile respectively.[122]\n",
      "Most of Pittsburgh's immigrants are from China, India, Korea and Italy.[123]\n",
      "Since the 1940s, city initiatives for redevelopment have driven demographic changes in Pittsburgh. In the 1950s, the Lower Hill District underwent significant upheaval when 1,551 mostly Black residents and 413 businesses were displaced for the construction of the Civic Arena, which opened in 1961.[13] This project, part of Pittsburgh's revitalization efforts, led to the neighborhood's population dropping to an estimated 12,000 today.[124]\n",
      "In the 1960s, the Urban Redevelopment Authority of Pittsburgh (URA) aimed to revitalize East Liberty, resulting in the construction of Penn Center Mall and the displacement of about 3,800 people.[125] By the early 2000s, private developers catering to a wealthier demographic introduced businesses like Home Depot, Whole Foods, and Google. This redevelopment, supported by the URA, transformed East Liberty into a desirable area for millennials.[125]\n",
      "These changes have sparked criticism, with some residents arguing that the government's actions were part of a strategy to disperse Black and low-income populations or facilitate gentrification of neighborhoods.[124][126] The demolition of housing units like the East Mall public housing complex in 2009, replaced by businesses like Target, is cited as evidence of this process.[127]\n",
      "According to a 2014 study by the Pew Research Center, 78% of the population of the city identified themselves as Christians, with 42% professing attendance at a variety of churches that could be considered Protestant, and 32% professing Catholic beliefs. while 18% claim no religious affiliation. The same study says that other religions (including Judaism, Buddhism, Islam, and Hinduism) collectively make up about 4% of the population.[128]\n",
      "According to a 2010 Association of Religion Data Archives (ARDA) study, residents include 773,341 \"Catholics\"; 326,125 \"Mainline Protestants\"; 174,119 \"Evangelical Protestants;\" 20,976 \"Black Protestants;\" and 16,405 \"Orthodox Christians,\" with 996,826 listed as \"unclaimed\" and 16,405 as \"other\" in the metro area.[118] A 2017 study by the Cohen Center for Modern Jewish Studies at Brandeis University estimated the Jewish population of Greater Pittsburgh was 49,200.[129] Pittsburgh is also cited as the location where the earliest precursor to Jehovah's Witnesses was founded by Charles Taze Russell; today the denomination makes up approximately 1% of the population based on data from the Pew Research Center.[130][131]\n",
      "Pittsburgh has adapted since the collapse of its century-long steel and electronics industries. The region has shifted to high technology, robotics, health care, nuclear engineering, tourism, biomedical technology, finance, education, and services. Annual payroll of the region's technology industries, when taken in aggregate, exceeded $10.8 billion in 2007,[132] and in 2010 there were 1,600 technology companies.[133] A National Bureau of Economic Research 2014 report named Pittsburgh the second-best U.S. city for intergenerational economic mobility[134] or the American Dream.[135] Reflecting the citywide shift from industry to technology, former factories have been renovated as modern office space. Google has research and technology offices in a refurbished 1918–1998 Nabisco factory, a complex known as Bakery Square.[136] Some of the factory's original equipment, such as a large dough mixer, were left standing in homage to the site's industrial roots.[137] Pittsburgh's transition from its industrial heritage has earned it praise as \"the poster child for managing industrial transition\".[138] Other major cities in the northeast and mid-west have increasingly borrowed from Pittsburgh's model in order to renew their industries and economic base.[139]\n",
      "The largest employer in the city is the University of Pittsburgh Medical Center, with 48,000 employees. All hospitals, outpatient clinics, and doctor's office positions combine for 116,000 jobs, approximately 10% of the jobs in the region. An analyst recently observed of the city's medical sector: \"That's both more jobs and a higher share of the region's total employment than the steel industry represented in the 1970s.\"[140]\n",
      "Education is a major economic driver in the region. The largest single employer in education is the University of Pittsburgh, with 10,700 employees.[141]\n",
      "Ten Fortune 500 companies call the Pittsburgh area home.[142] They are (in alphabetical order):  Alcoa Corporation (NYSE: AA), Arconic Corporation (NYSE: ARNC), Dick's Sporting Goods (NYSE: DKS),  The Kraft Heinz Company (NASDAQ: KHC), PNC Financial Services (NYSE: PNC), PPG Industries (NYSE: PPG), U.S. Steel Corporation (NYSE: X), Viatris (NASDAQ: VRTS), Wabtec Corporation (NYSE: WAB), and WESCO International (WYSE: WCC).[143]\n",
      "The region is home to Aurora, Allegheny Technologies, American Eagle Outfitters, Duolingo, EQT Corporation, CONSOL Energy, Howmet Aerospace, Kennametal and II-VI headquarters. Other major employers include BNY Mellon, GlaxoSmithKline, Thermo Fisher Scientific, and Lanxess. The Northeast U.S. regional headquarters for Chevron Corporation, Nova Chemicals, Deloitte Touche Tohmatsu, FedEx Ground, Ariba, and the RAND Corporation call the area home. 84 Lumber, Giant Eagle, Highmark, Rue 21, General Nutrition Center (GNC), CNX Gas (CXG), and Genco Supply Chain Solutions are major non-public companies headquartered in the region. The global impact of Pittsburgh technology and business was recently demonstrated in several key components of the Boeing 787 Dreamliner being manufactured and supplied by area companies.[144] Area retail is anchored by over 35 shopping malls and a healthy downtown retail sector, as well as boutique shops along Walnut Street, in Squirrel Hill, Lawrenceville and Station Square.\n",
      "The nonprofit arts and cultural industry in Allegheny County generates $341 million in economic activity that supports over 10,000 full-time equivalent jobs with nearly $34 million in local and state taxes raised.[145]\n",
      "A leader in environmental design, the city is home to 60 total and 10 of the world's first green buildings while billions have been invested in the area's Marcellus natural gas fields.[146] A renaissance of Pittsburgh's 116-year-old film industry—that boasts the world's first movie theater—has grown from the long-running Three Rivers Film Festival to an influx of major television and movie productions. including Disney and Paramount offices with the largest sound stage outside Los Angeles and New York City.[147]\n",
      "Pittsburgh has hosted many conventions, including INPEX, the world's largest invention trade show, since 1984;[148] Tekko, a four-day anime convention, since 2003; Anthrocon, a furry convention, since 2006; and the DUG East energy trade show since 2009.\n",
      "In 2015, Pittsburgh was listed among the \"eleven most livable cities in the world\" by Metropolis magazine.[149][150] The Economist's Global Liveability Ranking placed Pittsburgh as the most or second-most livable city in the United States in 2005, 2009, 2011, 2012, 2014, and 2018.[151][152]\n",
      "Pittsburgh boasts a rich arts and culture scene, with a history dating back to 19th-century industrialists who commissioned and donated public works including Heinz Hall for the Performing Arts and the Benedum Center, home to the Pittsburgh Symphony Orchestra and Pittsburgh Opera. Other prominent groups include the River City Brass Band and Pittsburgh Youth Symphony Orchestra. The city also hosts a variety of smaller arts organizations, such as Pittsburgh Irish and Classical Theatre, Quantum Theatre, the Renaissance and Baroque Society of Pittsburgh, and Chatham Baroque, an early music ensemble. University choirs include the Pitt Men's Glee Club and Heinz Chapel Choir.\n",
      "The Pittsburgh Ballet Theatre and Pittsburgh Dance Council offer diverse dance events, while polka, folk, square, and round dancing are celebrated by the Duquesne University Tamburitzans, a multicultural academy dedicated to folk traditions. Pittsburgh is also a popular filming location, with major productions like The Dark Knight Rises filmed in Downtown, Oakland, and the North Shore. The city is also recognized as the birthplace of the modern zombie film genre after George A. Romero's 1968 film Night of the Living Dead.[153][154]\n",
      "Major art museums include the Andy Warhol Museum, the Carnegie Museum of Art, The Frick Pittsburgh, Pittsburgh Center for the Arts, the Mattress Factory, and the Carnegie Museum of Natural History, which holds extensive dinosaur, mineral, and Egyptian collections. The Kamin Science Center and associated SportsWorks offer interactive technology and science exhibits. The Heinz History Center, a Smithsonian affiliate, provides regional history in the Strip District, while the Fort Pitt Museum is located in Point State Park. The Soldiers and Sailors Memorial Hall and Museum houses military exhibits, and the Children's Museum of Pittsburgh features interactive exhibits for kids. The eclectic Bayernhof Music Museum is located six miles (9 km) from downtown, while The Clemente Museum is in Lawrenceville. The Cathedral of Learning's Nationality Rooms  showcase pre-19th-century learning environments, and architectural tours are available in many neighborhoods. Downtown's cultural district hosts quarterly Gallery Crawls and the annual Three Rivers Arts Festival. Pittsburgh also has art galleries such as the Miller Gallery at Carnegie Mellon University, University Art Gallery of the University of Pittsburgh, the American Jewish Museum, and the Wood Street Galleries.\n",
      "Pittsburgh is home to the Pittsburgh Zoo & Aquarium, Phipps Conservatory and Botanical Gardens, and the National Aviary, all over a century old. Kennywood, a classic amusement park, is located in West Mifflin, and the Rivers Casino is on the North Shore along the Ohio River, just west of Kamin Science Center and Acrisure Stadium.\n",
      "Pittsburgh hosts Anthrocon, the world's largest furry convention, which has been held annually at the David L. Lawrence Convention Center since 2006. In 2024, the event attracted over 17,000 visitors and has generated a cumulative economic impact of $53 million over 11 years.[155] Additionally, the reality show Dance Moms is filmed at Pittsburgh's Abby Lee Dance Company.\n",
      "Pittsburgh has a long tradition of jazz, blues, and bluegrass music. The National Negro Opera Company was founded in the city as the first all-African American opera company in the U.S., helping launch the careers of African-American opera stars like Leontyne Price. Pittsburgh also shaped 20th-century music with influential figures like Billy Strayhorn, who grew up in the city, and pianist-composer Mary Lou Williams, who honored her hometown with a 1966 album featuring Leon Thomas.[156] featuring vocalist Leon Thomas.[157]\n",
      "Recent artists like Wiz Khalifa have continued Pittsburgh's musical legacy, with his hit Black and Yellow reaching number one on the Billboard Hot 100 in 2011.[158] Other notable artists from the area include Perry Como, Christina Aguilera, and the band Rusted Root, which was formed in Pittsburgh. Rusted Root's Liz Berlin owns Mr. Smalls, a popular venue for national touring acts.[159] Hip hop artist Mac Miller, also from Pittsburgh, named his debut album Blue Slide Park after the local Frick Park.\n",
      "Pittsburgh has emerged as a leading city in the United States' heavy metal music scene.[160][161] Many punk rock and Hardcore punk acts, such as Aus Rotten and Anti-Flag, originated in Pittsburgh. Pittsburgh has also seen many metal bands gain prominence in recent years,[when?] most notably Code Orange, who were nominated for a Grammy. The city was also home to the highly influential math rock band Don Caballero.\n",
      "Pittsburgh also had an influential electronic music subculture in the 1990s, with origins similar to internet chatroom-based movements across the United States.[162][163][164] Pittsburgh promoters and DJs organized raves in warehouses, ice rinks, barns, and fields which eventually attracted thousands of attendees.[163][165][166] DJs Adam Beyer and Richie Hawtin played at local raves.[163] One notable figure, drum and bass DJ Dieselboy, emerged from this scene.[162][167] Since 2012, the Hot Mass after-hours electronic music dance party has been a key part of Pittsburgh's electronic music scene, noted for its European nightclub vibe.[168][169] Electronic artist Yaeji has credited Hot Mass as a formative influence during her time at Carnegie Mellon University.[170][171]\n",
      "The city's first play was produced at the old courthouse in 1803[26] and the first theater built in 1812.[26] Collegiate companies include the University of Pittsburgh's Repertory Theatre and Kuntu Repertory Theatre, Point Park University's resident companies at its Pittsburgh Playhouse, and Carnegie Mellon University's School of Drama productions and Scotch'n'Soda organization. The Duquesne University Red Masquers, founded in 1912, are the oldest, continuously producing theater company in Pennsylvania.[citation needed] The city's longest-running theater show, Friday Nite Improvs, is an improv jam that has been performed in the Cathedral of Learning and other locations for 20 years. The Pittsburgh New Works Festival utilizes local theater companies to stage productions of original one-act plays by playwrights from all parts of the country. Similarly, Future Ten showcases new ten-minute plays. Saint Vincent Summer Theatre, Off the Wall Productions, Mountain Playhouse, The Theatre Factory, and Stage Right! in nearby Latrobe, Carnegie, Jennerstown, Trafford, and Greensburg, respectively, employ Pittsburgh actors and contribute to the culture of the region.\n",
      "Pittsburgh is well known for being home to the late playwright August Wilson.[172] The August Wilson House now remains in Pittsburgh to celebrate the life and work of August Wilson, continue to produce his plays, and serve as an arts center for the Hill District, where Wilson was from.[172]\n",
      "Pittsburgh is the birthplace of notable writers such as Gertrude Stein and Rachel Carson, a Chatham University graduate from the suburb of Springdale, Pennsylvania.[173] Modern writers include Pulitzer Prize-winning playwright August Wilson, as well as Michael Chabon, who writes about student and college life in Pittsburgh.[174] Two-time Pulitzer winner and recipient of the Presidential Medal of Freedom, David McCullough, was born and raised in Pittsburgh.[175] Pulitzer Prize-winning author Annie Dillard, whose memoir An American Childhood takes place in post-World War II Pittsburgh, also hails from the city.\n",
      "Award-winning author John Edgar Wideman, who grew up in Pittsburgh, has based several books in the city, including Brothers and Keepers. Poet Terrance Hayes, winner of the 2010 National Book Award and a 2014 MacArthur Foundation Fellow, earned his MFA at the University of Pittsburgh and was a faculty member there. Other local poets include Michael Simms, founder of Autumn House Press, and Samuel John Hazo, Pennsylvania's first poet laureate. Contemporary writers like Kathleen Tessaro, author of novels such as Elegance, The Perfume Collector, and Rare Objects, and new authors including Chris Kuzneski and Brian Celio, who captures Pittsburgh's \"Yinzer\" dialect, contribute to the city's vibrant literary tradition. Pittsburgh's unique literary style extends to playwrights,[176] as well as local graffiti and hip hop artists.\n",
      "Pittsburgh's position as the birthplace for community-owned television and networked commercial television helped spawn the modern children's show genres exemplified by Mister Rogers' Neighborhood, Where in the World is Carmen Sandiego?, Happy's Party, Cappelli & Company, and The Children's Corner, all nationally broadcast.\n",
      "The Pittsburgh Dad series has showcased the Pittsburghese genre to a global YouTube audience since 2011.\n",
      "The modern fantasy, macabre and science fiction genre was popularized by director George A. Romero, television's Bill Cardille and his Chiller Theatre,[177] director and writer Rusty Cundieff and makeup effects guru Tom Savini.[178] The genre continues today with the PARSEC science fiction organization,[179] The It's Alive Show, the annual \"Zombie Fest\",[180] and several writer's workshops including Write or Die,[181] Pittsburgh SouthWrites,[182] and Pittsburgh Worldwrights[183][184] with Barton Paul Levenson, Kenneth Chiacchia and Elizabeth Humphreys Penrose.\n",
      "Pittsburgh is known for several specialties including pierogies, kielbasa, chipped chopped ham sandwiches, and Klondike bars.[185][186] In 2019, Pittsburgh was deemed \"Food City of the Year\" by the San Francisco-based restaurant and hospitality consulting firm af&co.[187] Many restaurants were favorably mentioned, among them were Superior Motors in Braddock, Driftwood Oven in Lawrenceville, Spork in Bloomfield, Fish nor Fowl in Garfield, Bitter Ends Garden & Luncheonette in Bloomfield, and Rolling Pepperoni in Lawrenceville.[188]\n",
      "Pittsburgh is home to the annual pickle-themed festival Picklesburgh, which has been named the \"best specialty food festival in America\".[189]\n",
      "The Pittsburgh English dialect, commonly called Pittsburghese, was influenced by Scots-Irish, German, and Eastern European immigrants and African Americans.[190] Locals who speak the dialect are sometimes referred to as \"Yinzers\" (from the local word \"yinz\" [var. yunz], a blended form of \"you ones\", similar to \"y'all\" and \"you all\" in the South). Common Pittsburghese terms are: \"slippy\" (slippery), \"redd up\" (clean up), \"jagger bush\" (thorn bush), and \"gum bands\" (rubber bands). The dialect is also notable for dropping the verb \"to be\". In Pittsburghese one would say \"the car needs washed\" instead of \"needs to be washed\", \"needs washing\", or \"needs a wash.\" The dialect has some tonal similarities to other nearby regional dialects of Erie and Baltimore but is noted for its somewhat staccato rhythms. The staccato qualities of the dialect are thought to originate either from Welsh or other European languages. The many local peculiarities have prompted The New York Times to describe Pittsburgh as \"the Galapagos Islands of American dialect\".[191] The lexicon itself contains notable loans from Polish and other European languages; examples include babushka, pierogi, and halušky.[192]\n",
      "Pittsburgh has five city parks and several parks managed by the Nature Conservancy. The largest, Frick Park, provides 664 acres (269 ha) of woodland park with extensive hiking and biking trails throughout steep valleys and wooded slopes. Birding enthusiasts visit the Clayton Hill area of Frick Park, where over 100 species of birds have been recorded.[193]\n",
      "Residents living in extremely low-lying areas near the rivers or one of the 1,400 creeks and streams may have occasional floods,[194] such as those caused when the remnants of Hurricane Ivan hit rainfall records in 2004.[195] River flooding is relatively rare due to federal flood control efforts extensively managing locks, dams, and reservoirs.[194][196][197] Residents living near smaller tributary streams are less protected from occasional flooding. The cost of a comprehensive flood control program for the region has been estimated at a prohibitive $50 billion.[194]\n",
      "Pittsburgh has the greatest number of bars per capita in the nation.[16]\n",
      "Pittsburgh hosted the first professional football game and the first World Series. In 2009, Pittsburgh won the Sporting News title of \"Best Sports City\" in the United States[198] and, in 2013, Sperling's Best Places \"top 15 cities for baseball\".[199] College sports also have large followings with the University of Pittsburgh in football and sharing Division I basketball fans with Robert Morris and Duquesne.\n",
      "Pittsburgh has a long history with its major professional sports teams—the Steelers of the National Football League, the Penguins of the National Hockey League, and the Pirates of Major League Baseball—which all share the same team colors, the official city colors of black and gold.[f] Pittsburgh is the only city in the United States where this practice of sharing team colors in solidarity takes place.[200] The black-and-gold color scheme has since become widely associated with the city and personified in its famous Terrible Towel.[201] Further, the Pittsburgh Riverhounds professional soccer team of the USL Championship division wear black and gold colors.\n",
      "\"Rails to Trails\", has converted miles of former rail tracks to recreational trails, including a Pittsburgh-Washington D.C. bike/walking trail.[202] Several mountain biking trails are within the city and suburbs, Frick Park has biking trails and Hartwood Acres Park has many miles of single track trails.[203][204]\n",
      "Major league\n",
      "Minor league/other\n",
      "**Pittsburgh's ABA franchise won the 1968 title, but the Steel City Yellow Jackets franchise is heir to it only in location.\n",
      "Power 5\n",
      "Other\n",
      "[t]his is the perfect blend of location, history, design, comfort and baseball ... The best stadium in baseball is in Pittsburgh.\n",
      "The Pittsburgh Pirates baseball team, often referred to as the Bucs or the Buccos (derived from buccaneer), is the city's oldest professional sports franchise, having been founded in 1881, and plays in the Central Division of the National League. The Pirates are nine-time Pennant winners and five-time World Series Champions, were in the first World Series (1903) and claim two pre-World Series titles in 1901 and 1902. The Pirates play in PNC Park.\n",
      "Pittsburgh also has a rich Negro league history, with the former Pittsburgh Crawfords and the Homestead Grays credited with as many as 14 league titles and 11 Hall of Famers between them in the 1930s and 1940s, while the Keystones fielded teams in the 1920s. In addition, in 1971 the Pirates were the first Major League team to field an all-minority lineup. One sportswriter claimed, \"No city is more synonymous with black baseball than Pittsburgh.\"[205]\n",
      "Since the late 20th century, the Pirates had three consecutive National League Championship Series appearances (1990–92) (going 6, 7 and 7 games each), followed by setting the MLB record for most consecutive losing seasons, with 20 from 1993 until 2012. This era was followed by three consecutive postseason appearances: the 2013 National League Division Series and the 2014–2015 Wild Card games. Their September pennant race in 1997 featured the franchises' last no-hitter and last award for Sporting News' Executive of the Year.[206]\n",
      "The city's professional team, NFL's Pittsburgh Steelers, is named after the distribution company the Pittsburgh Steeling company established in 1927. News of the team has preempted news of elections and other events and are important to the region and its diaspora. The Steelers have been owned by the Rooney family since the team's founding in 1933, show consistency in coaching (only three coaches since the 1960s all with the same basic philosophy) and are noted as one of sports' most respectable franchises.[207] The Steelers have a long waiting list for season tickets, and have sold out every home game since 1972.[208] The team won four Super Bowls in a six-year span in the 1970s, a fifth Super Bowl in 2006, and a league record sixth Super Bowl in 2009.\n",
      "College football in the city dates to 1889[209] with the Division I (FBS) Panthers of the University of Pittsburgh posting nine national championships, qualifying 37 total bowl games, appearing in the 2018 ACC Championship Game, and winning the 2021 ACC Championship Game which was the program's first conference title since leaving the Big East for the ACC between the 2012 and 2013 seasons.[210] Local universities Duquesne and Robert Morris have loyal fan bases that follow their lower (FCS) teams.\n",
      "Acrisure Stadium serves as home for the Steelers, Panthers, and both the suburban and city high school championships. Playoff franchises Pittsburgh Power and Pittsburgh Gladiators competed in the Arena Football League in the 1980s and 2010s respectively. The Gladiators hosted ArenaBowl I in the city, competing in two, but losing both before moving to Tampa, Florida and becoming the Storm.[211] The Pittsburgh Passion has been the city's professional women's football team since 2002 and plays its home games at Highmark Stadium. The Ed Debartolo owned Pittsburgh Maulers featured a Heisman Trophy winner in the mid-1980s, former superstar University of Nebraska running back Mike Rozier.\n",
      "The NHL's Pittsburgh Penguins have played in Pittsburgh since the team's founding in 1967. The team has won 6 Eastern Conference titles (1991, 1992, 2008, 2009, 2016 and 2017) and 5 Stanley Cup championships (1991, 1992, 2009, 2016 and 2017). Since 1999, Hall of Famer and back-to-back playoff MVP Mario Lemieux has served as Penguins owner. Until moving into the PPG Paints Arena in 2010 (when it was known as Consol Energy Center), the team played their home games at the world's first retractable domed stadium, the Civic Arena, or in local parlance \"The Igloo\".[212]\n",
      "Ice hockey has had a regional fan base since the 1890s semi-pro Keystones. The city's first ice rink dates back to 1889, when there was an ice rink at the Casino in Schenley Park. From 1896 to 1956, the Exposition Building on the Allegheny River near The Point and Duquesne Gardens in Oakland offered indoor skating.[213]\n",
      "The NHL awarded one of its first franchises to the city in 1924 on the strength of the back-to-back USAHA championship-winning Pittsburgh Yellow Jackets. The NHL's Pittsburgh Pirates made several Stanley Cup playoff runs before folding from Great Depression financial pressures. Hockey survived with the Pittsburgh Hornets farm team (1936–1967) and their seven finals appearances and three championships in 18 playoff seasons.\n",
      "Robert Morris University fields a Division I college hockey team at the Island Sports Center. Pittsburgh has semi-pro and amateur teams such as the Pittsburgh Penguins Elite.[214] Pro-grade ice rinks in the region include the Rostraver Ice Garden and Iceoplex at Southpointe.\n",
      "Professional basketball in Pittsburgh dates to the 1910s with teams \"Monticello\" and \"Loendi\" winning five national titles, the Pirates (1937–45 in the NBL), the Pittsburgh Ironmen (1947–48 NBA inaugural season), the Pittsburgh Rens (1961–63), the Pittsburgh Pipers (first American Basketball Association championship in 1968) led by Connie Hawkins (team then moved); the Pittsburgh Condors (ABA returned in 1970–72), the Pittsburgh Piranhas (CBA Finals in 1995), the Pittsburgh Xplosion (2004–08) and Phantoms (2009–10) both of the ABA.\n",
      "Three Pittsburgh universities, the University of Pittsburgh, Duquesne University, and Robert Morris University, compete in NCAA Division I basketball. Pitt and Duquesne are the traditional basketball powers in the city, but all three universities have made multiple appearances in the National Invitation Tournament and NCAA tournament. Pitt won two pre-NCAA tournament National Championships in 1928 and 1930[215] while Duquesne won the NIT title in 1955, its second straight trip to the NIT title game. Both Pitt and Duquesne have reached the NCAA tournament Final Four once, Duquesne in 1940 and Pitt in 1941.\n",
      "Pittsburgh Panthers women's basketball has qualified for 14 post season tournaments (including 4 NCAA tournaments) and boasts of 5 All-Americans selected 6 times with 3 WNBA players. Pitt women began play in 1914 before being reintroduced in 1970. Both Duquesne and Robert Morris also have competitive Division I women's basketball programs.\n",
      "The Riverhounds, an American professional soccer team, were founded in 1998. Like the major league teams in the city, the Riverhounds wear black and gold kits. The club plays in the Eastern Conference of the USL Championship, the second tier of the American soccer pyramid. The Riverhounds play their home games at Highmark Stadium, a soccer-specific stadium located in Station Square.[citation needed]\n",
      "Golf has deep roots in the area. The oldest U.S. course in continuous use, Foxburg Country Club dating from 1887 calls the region home.[216] Suburban Oakmont Country Club holds the record for most times as host for the U.S. Open at nine; it has also hosted the U.S. Women's Open, PGA Championships, and U.S. Amateurs.[217]\n",
      "Golf legends Arnold Palmer, Jim Furyk, and Rocco Mediate learned the game and began their careers on Pittsburgh area courses.[218] Suburban courses such as Laurel Valley Golf Club and the Fox Chapel Golf Club have hosted PGA Championships (1937, 1965), the Ryder Cup (1975), LPGA Championships (1957–58), Senior Players Championships (2012–14), and the Senior PGA Championship (2005).\n",
      "Local courses have sponsored annual major tournaments for 40 years:\n",
      "Many notable professional wrestlers and promoters have hailed from the city or started their careers in Pittsburgh, including Bruno Sammartino, Kurt Angle, Shane Douglas, Corey Graves, Dominic DeNucci, Elias, Britt Baker and many more.\n",
      "The Fineview section of Pittsburgh served as the base of the televised show Studio Wrestling during the 1960s.[219][220] The Keystone State Wrestling Alliance (KSWA) is a professional wrestling promotion which was founded in Pittsburgh in 2000. It is the only promotion based in Pittsburgh. It operates in the city's Lawrenceville neighborhood. The KSWA performs Monthly on Saturdays at its main venue on 51st Street.\n",
      "Pittsburgh hosts several annual major sporting events initiated in the late 20th century, including the:\n",
      "The city's vibrant rivers have attracted annual world-title fishing competitions of the Forrest Wood Cup in 2009 and the Bassmaster Classic in 2005.\n",
      "Annual events continue during the winter months at area ski resorts such as Boyce Park, Seven Springs, Hidden Valley Resort, Laurel Mountain, and Wisp. Ice skating rinks are enjoyed at PPG Place and North Park.\n",
      "The Government of Pittsburgh is composed of the Mayor of Pittsburgh, the Pittsburgh City Council, and various boards and commissions. The mayor and the nine-member council each serve four-year terms. Since the 1950s the Mayor's Chief of Staff has assumed a large role in advising, long term planning, and as a \"gatekeeper\" to the mayor. City council members are chosen by plurality elections in each of nine districts. The government's official offices are in the Pittsburgh City-County Building.\n",
      "The Pennsylvania Supreme Court holds sessions in Pittsburgh, as well as Harrisburg and Philadelphia. Pittsburgh is represented in the Pennsylvania General Assembly by three Senate Districts and nine House Districts. Federally, Pittsburgh is part of Pennsylvania's 12th congressional district.\n",
      "In 2006, Council President Luke Ravenstahl was sworn in as mayor at age 26, becoming the youngest mayor in the history of any major American city. His successor, Bill Peduto, was sworn in on January 6, 2014. In November 2021, Pittsburgh elected its first African-American mayor, Ed Gainey.\n",
      "Prior to the American Civil War, Pittsburgh was strongly abolitionist. It is considered the birthplace of the national Republican Party,[221] as the party held its first convention here in February 1856. From the Civil War to the 1930s, Pittsburgh was a Republican stronghold. The effects of the Great Depression, combined with entrenched local GOP scandals, resulted in a shift among voters to the Democratic Party. With the exceptions of the 1973 and 1977 elections (where lifelong Democrats ran off the party ticket), Democrats have been elected consecutively to the mayor's office since the 1933 election. The city's ratio of party registration is 5 to 1 Democrat.[222]\n",
      "Pittsburgh is represented in the Pennsylvania General Assembly by three Senate Districts (Lindsey Williams (D)-38, Wayne D. Fontana (D)-42, and Jay Costa (D)-43) and nine House Districts (Aerion Abney-19, Emily Kinkead-20, Lindsay Powell-21, Dan Frankel-23, La'Tasha Mayes-24, Dan Deasy-27, Abigail Salisbury-34, Jessica Benham-36, and John Inglis-38).\n",
      "Federally, Pittsburgh is part of Pennsylvania's 12th congressional district, represented by Democrat Summer Lee since 2023.\n",
      "The area's largest law enforcement agency is the Pittsburgh Bureau of Police, with close to 850 sworn officers. The city also has separate housing and school police departments. Other agencies also provide police protection within the city because of overlapping jurisdictional boundaries. The Allegheny County Sheriff focuses on jail and courthouse security. The Allegheny County Police primarily patrols county-owned parks and airports, while providing detective/investigatory functions for smaller suburbs and the Port Authority police patrols rapid transit. Pennsylvania State Police Troop B provides patrols for the city and immediate suburbs.\n",
      "The county's lead law enforcement officer is Allegheny County District Attorney Stephen Zappala while the Allegheny County Medical Examiner heads forensics. Crimes of a federal nature are covered by the U.S. Attorney for Western Pennsylvania.\n",
      "Pittsburgh annually ranks as one of America's safest big cities, in 2013 being named the 3rd \"most secure\" big city by Farmers Insurance.[223] Among crime rates of the 60 largest U.S. cities, 43 had more instances of property crime while 16 had less when compared to Pittsburgh. More instances of violent crime were reported in 21 of the largest cities while 37 had less. The FBI recommends against using data for ranking.[224][225]\n",
      "Per 100,000 persons stats (2012):\n",
      "At the end of 2019, the Pittsburgh Bureau of Police reported 37 murders in the city that year.[226]\n",
      "In Pittsburgh, the homicide rate for African Americans is seven times the national average.[227] Some people believe that over-reliance on law enforcement exacerbates homicide rates.[227] There is also concern regarding the effectiveness of law enforcement in solving these cases, as 97% of unsolved cases involved a black victim.[228] This has led certain residents to believe law enforcement to be ineffective or apathetic.[228] This is despite an increasing police budget. In 2023, members of the Pittsburgh City Council approved an increase to the police budget by $6 million.[229] About 6% of this money is expected to go to the Stop the Violence trust fund. This fund goes to improving parks and recreation, various non-profits, and to the office of Community Health and Safety, in effort to holistically improve the social pressures supposedly causing violence in Pittsburgh.[230]\n",
      "Some people do not believe these efforts to be adequate. Certain studies, such as conducted by the Police Scorecard, rate the Pittsburgh Police Department at 37% quality (with 100% being the best). They rated Pittsburgh below the 50th percentile in the categories \"police budget cost per person,\" \"fines / forefeitures,\" \"Police Presence/Over-Policing (Officers per Population),\" \"Force Used per Arrest,\" \"Racial Disparities in Deadly Force,\" \"Excessive Force Complaints Upheld,\" \"Discrimination Complaints Upheld,\" \"Criminal Misconduct Complaints Upheld,\" \"Arrest Rate for Low Level Offenses,\" and \"Racial Disparities in Drug Arrests.\" This is 10 out of 15 categories.[231]\n",
      "Pittsburgh is home to many colleges, universities and research facilities, the most well-known of which are Carnegie Mellon University, the University of Pittsburgh, and Duquesne University. Also in the city are Carlow University, Chatham University, Point Park University, the Community College of Allegheny County, Pittsburgh Theological Seminary, Reformed Presbyterian Theological Seminary, and the Pittsburgh Institute of Mortuary Science.\n",
      "The campuses of Carlow, Carnegie Mellon, and the University of Pittsburgh are near each other in the Oakland neighborhood that is the city's traditional cultural center. Carnegie Mellon University (CMU) is a private research university founded by Andrew Carnegie and Andrew Mellon.[232] CMU contains the Mellon College of Science, School of Computer Science, College of Engineering, School of Business, Heinz College, College of Fine Arts, writing, Social and Decision Sciences, information systems, statistics, and psychology programs.\n",
      "The University of Pittsburgh, established in 1787 and popularly referred to as \"Pitt\", is a state-related school with one of the nation's largest research programs.[14] Pitt is known for the Kenneth P. Dietrich School of Arts and Sciences, University of Pittsburgh Graduate School of Public and International Affairs, University of Pittsburgh School of Information Sciences, Swanson School of Engineering, University of Pittsburgh College of Business Administration, University of Pittsburgh School of Law, University of Pittsburgh School of Medicine, University of Pittsburgh School of Social Work, and other biomedical and health-related sciences.[232][233][234][235][236]\n",
      "Carlow University is a small private Catholic university that while coeducational, has traditionally educated women. Chatham University, a liberal arts college that was founded as a woman's college but became fully coeducational in 2015,[237] is in the Shadyside neighborhood, but also maintains a 388-acre (157 ha) Eden Hall Farm campus in the North Hills. Duquesne University, a private Catholic university in the Bluff neighborhood and is noted for its song and dance troupe, the Duquesne University Tamburitzans, as well as programs in law, business, and pharmacy. Point Park University was founded in 1961 and is well known for its Conservatory of Performing Arts and its Pittsburgh Playhouse.\n",
      "Pittsburgh Public Schools teachers are paid well relative to their peers, ranking 17th in 2000 among the 100 largest cities by population for the highest minimum salary. In 2018, the starting teacher salary offered to teachers with a BA was $46,920. The maximum annual salary for a teacher with a master's degree was $95,254.[238]\n",
      "Local public schools include many charter and magnet schools, including City Charter High School (computer and technology focused), Pittsburgh Montessori School (formerly Homewood Montessori), Pittsburgh Gifted Center, Barack Obama Academy of International Studies 6-12, Pittsburgh Creative and Performing Arts 6–12, Pittsburgh Science and Technology Academy, the Western Pennsylvania School for Blind Children, and the Western Pennsylvania School for the Deaf.\n",
      "Private schools in Pittsburgh include Bishop Canevin High School, Central Catholic High School, Oakland Catholic High School, Winchester Thurston School, St. Edmund's Academy, Hillel Academy of Pittsburgh, Yeshiva Schools and The Ellis School. Shady Side Academy maintains a PK–5 primary school campus in the Point Breeze neighborhood, in addition to its 6–12 middle and upper school campuses in nearby suburban Fox Chapel. Other private institutions outside of Pittsburgh's limits include North Catholic High School and Seton-La Salle Catholic High School.\n",
      "The city also has an extensive library system, both public and university. Most notable are the Carnegie Library of Pittsburgh and the University of Pittsburgh's University Library System, which rank as the ninth-largest public and 18th-largest academic libraries in the nation, respectively.[239][240]\n",
      "There are two major daily newspapers in Pittsburgh: the Pittsburgh Post-Gazette and the Pittsburgh Tribune-Review online only (no longer in print for Pittsburgh Area). Weekly papers in the region include the Pittsburgh Business Times, Pittsburgh City Paper, Pittsburgh Catholic, Pittsburgh Jewish Chronicle, The New People, and the New Pittsburgh Courier. Independent student-written university-based newspapers include The Pitt News of the University of Pittsburgh, The Tartan of Carnegie Mellon University, The Duquesne Duke of Duquesne University, and The Globe of Point Park University. The University of Pittsburgh School of Law is also home to JURIST, the world's only university-based legal news service.[241]\n",
      "The Pittsburgh metro area is served by multiple local television and radio stations. The Pittsburgh designated market area (DMA) is the 22nd-largest in the U.S. with 1,163,150 homes (1.045% of the total U.S.).[242] The major network television stations include KDKA-TV 2 (CBS), WTAE 4 (ABC), WPXI 11 (NBC), WINP-TV 16 (Ion), WPKD-TV 19 (Independent), WPNT 22 (The CW/MyNetworkTV), WPCB 40 (Cornerstone), and WPGH-TV 53 (Fox). KDKA-TV, WINP-TV, and WPCB are owned-and-operated by their respective networks.\n",
      "WQED 13 is the local PBS member station in Pittsburgh. It was established on April 1, 1954, and was the first community-sponsored television station and the fifth public station in the United States. The station has produced much original content for PBS, including Mr. Rogers' Neighborhood, several National Geographic specials, and Where in the World is Carmen Sandiego?[243]\n",
      "A wide variety of radio stations serve the Pittsburgh market. The first was KDKA 1020 AM, also the world's first commercially licensed radio station, which began airing on November 2, 1920.[244] Other stations include KQV 1410 AM (news), WBGG 970 AM (sports), KDKA-FM 93.7 FM (sports), WKST-FM 96.1 FM (Top 40), WAMO-AM 660 AM and 107.3 FM (urban contemporary) WBZZ 100.7 FM (adult contemporary), WDVE 102.5 FM (album rock), WPGB 104.7 FM (Country), and WXDX 105.9 FM (modern rock). There are also three public radio stations in the area: WESA 90.5 FM (National Public Radio affiliate), WQED 89.3 FM (classical), and WYEP 91.3 FM (adult alternative). Three non-commercial stations are run by Carnegie Mellon University (WRCT 88.3 FM), the University of Pittsburgh (WPTS 92.1 FM), and Point Park University (WPPJ 670 AM).\n",
      "Pittsburgh's 116-year-old film industry accelerated after the 2006 passage of the Pennsylvania Film Production Tax Credit.[245] According to the Pittsburgh Film Office, over 124 major motion pictures have been filmed, in whole or in part, in Pittsburgh, including The Mothman Prophecies, Wonder Boys,[246] Dogma,[246] Hoffa, The Silence of the Lambs,[246] Sudden Death, Flashdance,[246] Southpaw, Striking Distance, Mrs. Soffel, Jack Reacher, Inspector Gadget, The Next Three Days, The Perks of Being a Wallflower,[246] Zack and Miri Make a Porno, and Fences.[246][247] Pittsburgh became \"Gotham City\" in 2011 during filming of The Dark Knight Rises.[147] George A. Romero shot nearly all his films in the area, including his Living Dead series.[248] From 2017 to 2023, Pittsburgh welcomed a series of major film and television productions like Fences, Mindhunter, Ma Rainey's Black Bottom, Sweet Girl, and I'm Your Woman, significantly contributing to the local economy.[249][250]\n",
      "Film production in Pittsburgh has notably impacted the region's economy and job creation, largely due to the 25% tax credit incentive established in 2007.[251][252] The Pittsburgh Film Office states that the film and television industry provides employment to over 10,000 people and pays over $500 million in wages in southwestern Pennsylvania.[253] Furthermore, the industry supports over 345,000 local businesses and contributes over $41 billion to them.[252]\n",
      "Pittsburgh is home to several film festivals, film schools, and organizations that encourage and promote independent and diverse filmmakers. Notable film festivals include the Three Rivers Film Festival, the Pittsburgh Shorts Film Festival, the JFilm Festival, the ReelAbilities Film Festival, and the Black Bottom Film Festival.[254][255] The local film schools include Pittsburgh Filmmakers, Point Park University - Cinema & Digital Arts, and University of Pittsburgh - Film Studies.[256][257]\n",
      "Moreover, Pittsburgh is developing a robust film studio infrastructure, with several sound stages and production facilities available for hire. Prominent film studios in Pittsburgh are 3 Rivers Studios, Cinelease Studios, Post Script Films, Deeplocal, and The Videohouse.[258][259][260][261][262] There are also plans in the pipeline to develop a new film studio complex at the Carrie Furnace site in Rankin and Swissvale.[263]\n",
      "The city is served by Duquesne Light, one of the original 1912 power companies founded by George Westinghouse.[264] Water service is provided by the Pittsburgh Water and Sewer Authority[265] and Pennsylvania American Water. Natural gas is provided by Equitable Gas, Columbia Gas, Dominion Resources, Direct Energy, and Novec.[266]\n",
      "The two largest area health care providers are the University of Pittsburgh Medical Center (UPMC) (since 1893) and Allegheny Health Network (since 1882). Both hospitals annually rank as among the best overall in the United States, with UPMC ranked among U.S. News & World Report's \"Honor Roll\" every year since 2000.[citation needed]\n",
      "The first military hospital in U.S. history and the first west of the Atlantic Plain—General Edward Hand Hospital—served the area from 1777 to 1845.[267] Since 1847, Pittsburgh has hosted the world's first \"Mercy Hospital\".[268] This was followed by West Penn hospital in 1848, Passavant Hospital in 1849,[26] the University of Pittsburgh School of Medicine in 1883, Children's Hospital in 1887, and Magee Womens Hospital in 1911. In 1954, Allegheny General (AGH) was among the first to administer Cobalt therapy.[269]\n",
      "In 1980, UPMC announced a $250 million ($1.08 billion today) expansion and also hired transplant pioneer Thomas Starzl.[270] In 1984, Allegheny General surgeons pioneered modern brain surgery. Starzl arranged the 1985 liver transplant of 5-year-old Amie Garrison as a UPMC surgery team flew to Baylor University, starting its transplant program.[271] Also in 1985, UPMC surgeons Drs. Griffith, Hardesty, and Trento revealed a new device after a heart-lung transplant. In 1986, UPMC announced a $230 million ($660 million today) modernization. In 1996, UPMC's planned Sicily ISMETT branch was approved by the Italian government as transplant surgeons to supervise and deliver the world's third (both earlier ones done at UPMC)--and first public—cross species marrow transplant at University of California, San Francisco.[272] UPMC's Thomas Detre founded the International Society for Bipolar Disorders at a world medical conference in Pittsburgh in 1999.[273]\n",
      "The $80 million ($146 million today) UPMC Sports Performance Complex for the Pittsburgh Panthers & Pittsburgh Steelers opened in 2000. In 2002, AGH opened its $30 million ($53.3 million today), 5-floor, 100,000 sq. ft., cancer center. The $130 million ($227 million today) 350,000 sq. ft. Hillman Cancer Center opened in 2003 as UPMC entered into an 8-year, $420 million ($699 million today) agreement with IBM to upgrade medical technologies & health information systems.[citation needed]\n",
      "In 2009, the $600 million ($876 million today) UPMC Children's Hospital of Pittsburgh opened. The campus was featured in world news in 2012 for several unique approaches to patient care.[274] UPMC officially adopted in Erie, Pennsylvania's Hamot Medical Center in 2010. The Pittsburgh Penguins announced a state of the art training facility with UPMC in 2012.[275] UPMC announced in 2013 it had partnered with Nazarbayev University to help found its medical school.[276]\n",
      "While he was a professor at the University of Pittsburgh, American virologist Jonas Salk developed one of the first successful polio vaccines, which came into use in 1955.\n",
      "UPMC has pioneered several world firsts including the first known cystic fibrosis heart-lung transplant (1983), the world's first simultaneous liver and heart transplant operation on a child (6-year-old Stormie Jones in 1984), the youngest heart-lung transplant (9 years old in 1985), the world's first heart-liver-kidney transplant (1989), the world's first heart-liver transplant on an infant (1997),[277] the first pediatric heart-double lung-liver transplant (1998), the nation's first double hand transplant (2009), and the first total forearm and hand transplant (2010), as well as the state's first heart transplant (1968).[278][279]\n",
      "The Lancet published a 2012 UPMC study of two 9-year quadriplegics being able to move a robotic arm by thought, to pick up objects, shake hands, and even eat. Wiring the brain around spine damage to restore arm and leg muscle function was successful using robotic arms controlled via an embedded computer to translate signals near a small group of neurons with 200 needles.[280]\n",
      "Pittsburgh is a city of bridges. With 446,[281] it has three bridges more than Venice, Italy, which has historically held the title \"City of Bridges.\"[282] Around 40 bridges cross the three rivers near the city. The Smithfield Street Bridge was the world's first lenticular truss bridge. The city's Three Sisters Bridges offer a picturesque view of the city from the North. The south-western \"entrance\" to Downtown for travelers coming in from Interstate 79 and the Pittsburgh International Airport is through the Fort Pitt Tunnel and over the Fort Pitt Bridge. The Fort Duquesne Bridge carrying Interstate 279 is the main gateway from Downtown to both PNC Park, Acrisure Stadium and the Rivers Casino. The Panhandle Bridge carries Pittsburgh Regional Transit's Blue/Red/Silver subway lines across the Monongahela River. The renovated J&L Steel Company bridge has been a key traffic/running-biking trail conduit connecting the Southside Works and Pittsburgh Technology Center. Over 2,000 bridges span the landscape of Allegheny County.[283]\n",
      "Pittsburgh is served by Pittsburgh Regional Transit, the 26th-largest transit agency in the country prior to the COVID-19 pandemic. The average amount of time people spend commuting with public transit in Pittsburgh, for example to and from work, on a weekday is 73 min. 23% of public transit riders ride for more than 2 hours every day. The average amount of time people wait at a stop or station for public transit is 17 minutes, while 33% of riders wait for over 20 minutes on average every day. The average distance people usually ride in a single trip with public transit is 3.9 mi (6.3 km), while 11% travel for over 7.5 mi (12 km) in a single direction.[284]\n",
      "Locals refer to the interstates fanning out from downtown Pittsburgh as the \"parkways.\" Interstate 376 is both the \"parkway east\" connecting to Interstate 76 (Pennsylvania Turnpike) and the \"parkway west\" connecting to Interstate 79, the Pittsburgh International Airport, the Ohio end of the Turnpike and Interstate 80. The \"parkway north\" is Interstate 279 connecting to I-79. The \"crosstown\" is Interstate 579 allowing access to the heart of downtown, the Liberty Tunnels and the PPG Paints Arena. The 45-mile-long and 70-mile-long expressway sections of Pennsylvania Route 28 and U.S. Route 22 also carry traffic from downtown to the northeast and western suburbs, respectively. Interstate 70, 79 and 76 (the Turnpike) roughly form a triangular-shaped \"beltway\" with Interstate 68 and 80 within the media market's northern and southern limits. Turnpike spurs such as the Mon–Fayette Expressway, Pennsylvania Route 576 and Route 66 also help traffic flow. The non-expressway Pittsburgh/Allegheny County Belt System serves navigation in the region.\n",
      "Pittsburgh International Airport provides commercial passenger service from over 15 airlines to the Pittsburgh metropolitan area. Arnold Palmer Regional Airport also provides limited commercial passenger service and is 44 miles (71 km) east of Pittsburgh.\n",
      "Other airports that have or have had scheduled commercial service include Morgantown Municipal Airport (79 miles (127 km) south of Pittsburgh), Youngstown–Warren Regional Airport (81 miles (130 km) northwest of Pittsburgh), Akron–Canton Airport (120 miles (190 km) northwest of Pittsburgh), Johnstown–Cambria County Airport (60 miles (97 km) east of Pittsburgh) and Erie International Airport (123 miles (198 km) north of Pittsburgh).\n",
      "Amtrak provides intercity rail service to Pittsburgh Union Station, via the Capitol Limited between Chicago and Washington, D.C., and the Pennsylvanian to New York City.\n",
      "Megabus, Greyhound Lines, and Fullington Trailways connect Pittsburgh with distant cities by bus; Greyhound and Fullington Trailways buses stop at the Grant Street Transportation Center intercity bus terminal. Popular destinations include Philadelphia, New York City, and Washington, D.C.[285]\n",
      "Until declines in passenger travel in the 1950s and 1960s, several stations served Pittsburgh: Baltimore & Ohio Station, Pittsburgh & Lake Erie Railroad Station, Wabash Pittsburgh Terminal and Pittsburgh Union Station.\n",
      "Pittsburgh Regional Transit, formerly known as the Port Authority of Allegheny County, is the region's mass transit system. While serving only a portion of the Pittsburgh area, the nation's 20th-largest metropolitan area, it is the 11th-largest transit agency in the United States.[286] Pittsburgh Regional Transit runs a network of intracity and intercity bus routes, the Monongahela Incline Funicular railway (more commonly known as an \"incline\") on Mount Washington, a light rail system that runs mostly above-ground in the suburbs and underground as a subway in the city, and one of the nation's largest busway systems.[287] Pittsburgh Regional Transit owns the Duquesne Incline but it is operated by a non-profit preservation trust,[288] but accepts Pittsburgh Regional Transit passes and charges PRT fares.\n",
      "The Bus System lines are labeled by number and letter. These are the largest portion of Pittsburgh Regional Transit and serve on streets and designated busways. Buses serve most of the county, extending as far as Pittsburgh International Airport, Monroeville, McCandless, and the borders of Westmoreland County and Beaver County, Pennsylvania. Meanwhile, the light rail system (commonly known as the \"T\") runs along both new tracks and those refurbished from the streetcar era. The light rail runs from Acrisure Stadium to South Hills Village and Library, taking commuters through one of two routes: one which serves Castle Shannon, Mt. Lebanon, and Beechview, and the other is an express line using railways through Overbrook.\n",
      "Pittsburgh's rail industry dates to 1851 when the Pennsylvania Railroad first opened service between the Pittsburgh and Philadelphia. The Baltimore and Ohio Railroad entered the city in 1871. In 1865, Andrew Carnegie opened the Pittsburgh Locomotive and Car Works, which manufactured for the industry until 1919. Carnegie also founded the Union Railroad in 1894 for heavy freight services and it still serves the area's steel industry, while George Westinghouse's Wabtec has been a leader in rail engines and switching since 1869.\n",
      "Pittsburgh is home to one of Norfolk Southern Railway's busiest freight corridors, the Pittsburgh Line, and operates up to 70 trains per day through the city. The suburban Conway Rail Yard, built in 1889, was the largest freight rail center in the world from 1956 until 1980 and is today the nation's second-largest. CSX, the other major freight railroad in the eastern U.S., also has major operations around Pittsburgh.\n",
      "The Port of Pittsburgh ranks as the 20th-largest port in the United States with almost 34 million short tons of river cargo for 2011. The port ranked ninth-largest in the U.S. when measured in domestic trade.[289]\n",
      "Pittsburgh's sister cities are:[290]\n"
     ]
    }
   ],
   "source": [
    "# Get all paragraph texts from the content\n",
    "paragraphs = content_div.find_all(\"p\")\n",
    "page_text = \"\\n\".join([p.get_text().strip() for p in paragraphs if p.get_text().strip() != \"\"])\n",
    "\n",
    "# Print or save the extracted text\n",
    "print(page_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, save the extracted text to a file\n",
    "with open(\"pittsburgh_wikipedia.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(page_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Converting .txt file into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=300):\n",
    "    \"\"\"\n",
    "    Splits the text into chunks, each containing approximately chunk_size words.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size):\n",
    "        chunk = \" \".join(words[i:i + chunk_size])\n",
    "        chunks.append(chunk)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the text from the file we saved earlier\n",
    "with open(\"pittsburgh_wikipedia.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Split the text into chunks of 300 words each\n",
    "chunks = chunk_text(text, chunk_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chunks: 42\n",
      "First chunk:\n",
      " Pittsburgh (/ˈpɪtsbɜːrɡ/ PITS-burg) is a city in and the county seat of Allegheny County, Pennsylvania, United States. It is the second-most populous city in Pennsylvania (after Philadelphia) and the 68th-most populous city in the U.S., with a population of 302,971 as of the 2020 census. The city is located in southwestern Pennsylvania at the confluence of the Allegheny River and Monongahela River, which combine to form the Ohio River.[7] It anchors the Pittsburgh metropolitan area, which had a population of 2.457 million residents and is the largest metro area in both the Ohio Valley and Appalachia, the second-largest in Pennsylvania, and the 26th-largest in the U.S. Pittsburgh is the principal city of the greater Pittsburgh–Weirton–Steubenville combined statistical area which includes parts of Ohio and West Virginia. Pittsburgh is known as \"the Steel City\" for its dominant role in the history of the U.S. steel industry.[8] It developed as a vital link of the Atlantic coast and Midwest, as the mineral-rich Allegheny Mountains led to the region being contested by the French and British empires, Virginians, Whiskey Rebels, and Civil War raiders.[9] For part of the 20th century, Pittsburgh was behind only New York City and Chicago in corporate headquarters employment; it had the most U.S. stockholders per capita.[10] Deindustrialization in the late 20th century resulted in massive layoffs among blue-collar workers as steel and other heavy industries declined, coinciding with several Pittsburgh-based corporations moving out of the city.[11] However, the city divested from steel and, since the 1990s, Pittsburgh has focused its energies on the healthcare, education, and technology industries.[12][13] Pittsburgh is home to large medical providers, including the University of Pittsburgh Medical Center and Allegheny Health Network, as well as 68 colleges and universities, including Carnegie Mellon University and the University of Pittsburgh.[14] The area has served as the\n"
     ]
    }
   ],
   "source": [
    "# Let's print out some info about our chunks\n",
    "print(\"Total number of chunks:\", len(chunks))\n",
    "print(\"First chunk:\\n\", chunks[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Converting Chunks to Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (3.4.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sentence-transformers) (4.49.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sentence-transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sentence-transformers) (0.28.1)\n",
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.0.12)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/jaipdalvi/Library/Python/3.13/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the chunks into embeddings\n",
    "chunk_embeddings = model.encode(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 42\n",
      "Embedding size for each chunk: 384\n",
      "[ 6.69733360e-02  9.13290586e-03  4.58831228e-02  5.95601015e-02\n",
      " -4.00966182e-02  1.80845428e-02 -7.55067915e-02 -2.86436491e-02\n",
      " -5.51363081e-02 -9.17582437e-02 -6.63802922e-02 -9.03211683e-02\n",
      "  2.78344061e-02  1.20455278e-02 -4.44494896e-02  4.48295958e-02\n",
      "  6.27688095e-02  5.60258701e-03  8.31092000e-02  5.27451895e-02\n",
      " -1.73825864e-02 -6.21511154e-02  3.66939902e-02 -2.30070259e-02\n",
      " -2.59499848e-02  7.56240040e-02 -2.11047214e-02  1.07153900e-01\n",
      " -3.77437449e-03  4.42617089e-02  3.32766213e-03 -3.95799130e-02\n",
      " -5.24191260e-02  2.78451554e-02  6.73767179e-02 -2.08626762e-02\n",
      " -7.25351200e-02  5.74528091e-02  4.32409253e-03  6.90284073e-02\n",
      " -9.64344293e-03  1.39100011e-02 -8.71037990e-02  5.46867959e-03\n",
      "  4.81062643e-02  9.01905820e-03 -6.50698915e-02  4.83859926e-02\n",
      " -7.85996299e-03 -7.95857832e-02  3.13218683e-02  2.03666482e-02\n",
      "  2.75037661e-02  4.57434766e-02  3.13159148e-03  1.47119537e-02\n",
      "  3.88591029e-02  8.17928985e-02 -1.59095917e-02  2.40707174e-02\n",
      "  1.26822535e-02  1.81505959e-02 -2.30993815e-02 -5.10442667e-02\n",
      "  6.64462671e-02  4.57993336e-02 -3.46994326e-02  6.10568039e-02\n",
      " -1.11027464e-01 -5.88644184e-02  7.11805001e-02  3.02812667e-03\n",
      " -8.77135321e-02  3.15907709e-02  7.04182461e-02 -5.50525561e-02\n",
      " -8.20811018e-02  3.02263014e-02 -3.68544720e-02  1.26243653e-02\n",
      "  4.29569222e-02 -3.30839828e-02 -5.97654805e-02 -4.74349968e-03\n",
      " -2.56904252e-02  7.11951032e-02 -6.59587830e-02  4.18328345e-02\n",
      " -2.92739235e-02 -4.36116941e-02 -2.07231063e-02  1.07423589e-02\n",
      " -9.21908095e-02 -2.46338043e-02  1.38702467e-01  4.08729240e-02\n",
      "  5.39033040e-02  2.59962697e-02  4.00476716e-02 -6.66517615e-02\n",
      "  5.09207994e-02 -1.69243980e-02 -5.84021211e-02 -6.36386052e-02\n",
      "  5.49845323e-02 -2.12257467e-02 -1.97751932e-02  8.27703476e-02\n",
      "  1.11104839e-03 -2.09209733e-02  2.86052525e-02  1.45363137e-02\n",
      " -4.63698767e-02 -3.51157039e-02  3.75485085e-02  3.66386101e-02\n",
      "  2.29418091e-02  1.99102052e-02  5.40917516e-02 -6.67109340e-03\n",
      " -2.51209382e-02  5.86099029e-02 -3.03493887e-02  9.83263850e-02\n",
      "  1.02687106e-01 -5.04346788e-02 -5.98822460e-02 -4.75805987e-33\n",
      " -1.25693008e-02 -2.94301081e-02  1.91169363e-02  4.82000485e-02\n",
      " -4.56650136e-03 -2.30175536e-02  5.51744848e-02 -7.78652430e-02\n",
      " -9.03397128e-02 -1.43445134e-02 -2.23662388e-02 -4.79668118e-02\n",
      " -3.70886177e-02 -4.21824446e-03  4.68599051e-02 -2.09561531e-02\n",
      " -4.78676520e-02 -1.50940316e-02 -7.89411142e-02 -2.02512536e-02\n",
      "  4.44251373e-02 -6.50368184e-02 -9.47184302e-03  1.46178722e-01\n",
      " -1.23325594e-01 -4.23438922e-02 -7.62550458e-02  8.21328908e-02\n",
      " -7.11211562e-02 -3.73999178e-02 -4.24460359e-02  5.51200807e-02\n",
      "  1.54233202e-02 -3.01175062e-02 -1.44747747e-02 -2.29454450e-02\n",
      "  3.46214697e-02  5.17462641e-02 -3.31808664e-02 -9.80237871e-03\n",
      " -1.77234989e-02  4.68616188e-03 -3.71236019e-02 -1.54053541e-02\n",
      "  5.87680265e-02 -9.62726399e-02 -5.50228811e-04 -1.54585494e-02\n",
      " -4.92685810e-02 -1.07774049e-01  5.12131788e-02 -2.73019075e-02\n",
      "  1.96837187e-02  1.84615552e-02 -3.42509411e-02  9.72610246e-03\n",
      "  9.75644141e-02 -2.68148407e-02  3.09670661e-02  6.77483231e-02\n",
      "  1.17376400e-02  3.25357430e-02 -2.03542691e-02  4.64678742e-03\n",
      "  2.67082918e-02 -1.26068639e-02  5.96625358e-02  1.10538252e-01\n",
      " -3.53089087e-02  1.10240974e-01  2.86100395e-02 -4.54300578e-04\n",
      "  6.99598119e-02  2.18941197e-02  8.34810138e-02  4.53997999e-02\n",
      " -4.84977104e-02  9.93817151e-02  4.57261093e-02  7.32260407e-04\n",
      "  3.92815396e-02 -5.67290857e-02 -3.36614624e-02  1.15890624e-02\n",
      "  8.19215029e-02 -7.84324929e-02  2.77405567e-02 -5.97344190e-02\n",
      "  2.30824519e-02  2.09625196e-02  2.75898874e-02 -4.14989106e-02\n",
      " -1.14445610e-03 -2.67489403e-02 -6.82578906e-02  1.96741516e-33\n",
      " -2.30542962e-02  6.00698851e-02  1.87387560e-02 -3.42945270e-02\n",
      " -5.58348522e-02 -3.81096676e-02  2.72093639e-02 -1.68304797e-02\n",
      "  2.96243373e-02 -1.37427812e-02 -2.89218817e-02 -3.07223015e-02\n",
      "  4.00280431e-02  7.74250254e-02  2.84874178e-02  9.35316458e-02\n",
      " -4.55220938e-02  3.49691771e-02 -1.04251988e-02 -3.14358957e-02\n",
      " -5.46653792e-02 -6.82042167e-02 -4.35167551e-02 -2.09871866e-02\n",
      " -3.12764011e-02 -3.12972479e-02 -8.50238949e-02 -1.03894226e-01\n",
      "  3.31495628e-02 -1.60615612e-02 -5.11884578e-02  6.58983039e-03\n",
      "  2.36269012e-02  1.32728191e-02  1.61097031e-02  1.56619120e-02\n",
      "  1.60921272e-02  8.26698542e-03  1.02901369e-01 -4.77441885e-02\n",
      " -1.00030072e-01 -3.20841596e-02 -2.34159976e-02  1.15668224e-02\n",
      "  7.06477687e-02  5.92342131e-02 -3.04772914e-03 -4.85104360e-02\n",
      " -7.37518221e-02  1.29983470e-01  6.58756569e-02  9.27043185e-02\n",
      "  3.68583612e-02  2.87876297e-02 -4.89072166e-02 -4.26453575e-02\n",
      " -1.26033574e-02  2.97087543e-02  2.53262594e-02 -6.01918474e-02\n",
      "  1.64086800e-02  7.00604916e-02 -5.92976660e-02  7.96743855e-02\n",
      "  1.32613420e-03  3.40040610e-03 -8.01906809e-02  1.42641952e-02\n",
      " -3.98901850e-02 -4.57999110e-02 -7.67103210e-02  4.17533144e-02\n",
      "  6.93928897e-02 -2.89270449e-02 -2.41133887e-02 -5.29643372e-02\n",
      "  2.64662039e-02  1.29139483e-01 -2.63135992e-02  1.28708035e-01\n",
      "  1.67358723e-02  3.45113017e-02  1.99877508e-02 -4.07207496e-02\n",
      " -4.86064069e-02  3.00621074e-02  1.44549524e-02  6.95466343e-03\n",
      " -2.25657225e-02 -7.34576359e-02 -5.00197411e-02 -2.39931997e-02\n",
      " -9.52300727e-02 -7.61358365e-02  5.14385873e-04 -5.13665732e-08\n",
      " -1.80753097e-02 -1.55911210e-03 -5.65666705e-02  3.32993492e-02\n",
      "  7.79754668e-02 -6.23060018e-02  1.87236238e-02  7.68110752e-02\n",
      "  2.96077039e-02  8.06221645e-03  2.24847556e-03  1.82453229e-03\n",
      " -1.81835704e-02 -7.22430125e-02 -4.16315943e-02  3.78923083e-04\n",
      " -5.57636060e-02 -3.20158340e-02  7.21986219e-02  2.37648841e-02\n",
      "  1.46059040e-02  1.15294689e-02 -4.27640218e-04  3.51223089e-02\n",
      "  2.55537797e-02 -8.65622163e-02 -1.10903159e-02 -4.21909541e-02\n",
      " -3.63898836e-02  1.25860255e-02  2.57939044e-02 -3.37090269e-02\n",
      " -7.90814683e-03  2.04678886e-02  1.39163882e-02 -1.70028731e-02\n",
      " -5.28428368e-02  1.18387258e-02  2.57491581e-02 -3.43759693e-02\n",
      " -1.47997988e-02 -2.04781275e-02  3.16152372e-03 -1.59080606e-02\n",
      "  4.57947664e-02  3.87963979e-03 -3.49901617e-02 -2.11455841e-02\n",
      "  8.70242491e-02 -4.92380001e-02 -4.56208922e-02 -6.17541969e-02\n",
      "  8.58978555e-02 -7.43723139e-02  1.30824530e-02  1.55306578e-01\n",
      "  5.39926775e-02 -3.63495946e-02  6.07257448e-02 -9.01292861e-02\n",
      "  2.10298877e-02  8.00866038e-02  7.72874355e-02  3.34248990e-02]\n"
     ]
    }
   ],
   "source": [
    "# Let's see the shape of our embeddings\n",
    "print(\"Number of chunks:\", len(chunk_embeddings))\n",
    "print(\"Embedding size for each chunk:\", len(chunk_embeddings[0]))\n",
    "print(chunk_embeddings[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing in Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy embeddings and chunk mapping saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Convert embeddings to numpy array\n",
    "embeddings = np.array(chunk_embeddings)\n",
    "\n",
    "# Save the embeddings to a .npy file\n",
    "np.save('pittsburgh_embeddings.npy', embeddings)\n",
    "\n",
    "# Create a mapping of index to text chunk\n",
    "index_to_chunk = {i: chunks[i] for i in range(len(chunks))}\n",
    "\n",
    "# Save the mapping as a JSON file\n",
    "with open(\"index_to_chunk.json\", \"w\") as f:\n",
    "    json.dump(index_to_chunk, f, indent=4)\n",
    "\n",
    "print(\"NumPy embeddings and chunk mapping saved successfully.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most relevant chunk for the query:\n",
      " Pittsburgh (/ˈpɪtsbɜːrɡ/ PITS-burg) is a city in and the county seat of Allegheny County, Pennsylvania, United States. It is the second-most populous city in Pennsylvania (after Philadelphia) and the 68th-most populous city in the U.S., with a population of 302,971 as of the 2020 census. The city is located in southwestern Pennsylvania at the confluence of the Allegheny River and Monongahela River, which combine to form the Ohio River.[7] It anchors the Pittsburgh metropolitan area, which had a population of 2.457 million residents and is the largest metro area in both the Ohio Valley and Appalachia, the second-largest in Pennsylvania, and the 26th-largest in the U.S. Pittsburgh is the principal city of the greater Pittsburgh–Weirton–Steubenville combined statistical area which includes parts of Ohio and West Virginia. Pittsburgh is known as \"the Steel City\" for its dominant role in the history of the U.S. steel industry.[8] It developed as a vital link of the Atlantic coast and Midwest, as the mineral-rich Allegheny Mountains led to the region being contested by the French and British empires, Virginians, Whiskey Rebels, and Civil War raiders.[9] For part of the 20th century, Pittsburgh was behind only New York City and Chicago in corporate headquarters employment; it had the most U.S. stockholders per capita.[10] Deindustrialization in the late 20th century resulted in massive layoffs among blue-collar workers as steel and other heavy industries declined, coinciding with several Pittsburgh-based corporations moving out of the city.[11] However, the city divested from steel and, since the 1990s, Pittsburgh has focused its energies on the healthcare, education, and technology industries.[12][13] Pittsburgh is home to large medical providers, including the University of Pittsburgh Medical Center and Allegheny Health Network, as well as 68 colleges and universities, including Carnegie Mellon University and the University of Pittsburgh.[14] The area has served as the\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the embeddings and index-to-chunk mapping\n",
    "embeddings = np.load('pittsburgh_embeddings.npy')\n",
    "with open(\"index_to_chunk.json\", \"r\") as f:\n",
    "    index_to_chunk = json.load(f)\n",
    "\n",
    "# Load the same model used for encoding the chunks\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# User query\n",
    "query = \"Where is Pittsburgh located geographically?\"\n",
    "\n",
    "# Encode the query to an embedding\n",
    "query_embedding = model.encode([query])\n",
    "\n",
    "# Compute cosine similarity\n",
    "cosine_similarities = np.dot(embeddings, query_embedding.T).flatten()\n",
    "\n",
    "# Get the index of the most similar chunk\n",
    "most_similar_idx = np.argmax(cosine_similarities)\n",
    "\n",
    "# Retrieve the corresponding text chunk\n",
    "most_relevant_chunk = index_to_chunk[str(most_similar_idx)]\n",
    "\n",
    "print(\"Most relevant chunk for the query:\\n\", most_relevant_chunk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.6.0)\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (4.49.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jaipdalvi/Library/Python/3.13/lib/python/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->transformers) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch transformers\n",
    "%pip install sentencepiece\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Where is Pittsburgh located geographically?\n",
      "A: on the Allegheny Plateau\n",
      "\n",
      "Q: What are the major rivers that converge in Pittsburgh?\n",
      "A: Monongahela\n",
      "\n",
      "Q: Why is Pittsburgh known as the 'Steel City'?\n",
      "A: many Welsh people from the Merthyr steelworks\n",
      "\n",
      "Q: What is the historical significance of Pittsburgh in the industrial revolution?\n",
      "A: Andrew Carnegie opened the Pittsburgh Locomotive and Car Works, which manufactured for the industry until 1919\n",
      "\n",
      "Q: Who were the early settlers of Pittsburgh?\n",
      "A: Virginians, Whiskey Rebels, and Civil War raiders\n",
      "\n",
      "Q: What are the major educational institutions in Pittsburgh?\n",
      "A: Carnegie Museums of Pittsburgh\n",
      "\n",
      "Q: How has Pittsburgh's economy transitioned from manufacturing to technology and healthcare?\n",
      "A: manufacturing was key to growth of Pittsburgh\n",
      "\n",
      "Q: What are the popular cultural and tourist attractions in Pittsburgh?\n",
      "A: Harris as well as various African-American jazz clubs\n",
      "\n",
      "Q: What are the major sports teams based in Pittsburgh?\n",
      "A: Pittsburgh area, the Pittsburgh Penguins are an American professional soccer team based in the city.\n",
      "\n",
      "Q: How does Pittsburgh contribute to arts and theater?\n",
      "A: Civic Arena, which opened in 1961\n",
      "\n",
      "All answers saved in system_output.json.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a more powerful T5 model\n",
    "model_name = \"google/flan-t5-large\"  # Upgrade from 'base'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Load embeddings and index-to-chunk mapping\n",
    "embeddings = np.load('pittsburgh_embeddings.npy')\n",
    "with open(\"index_to_chunk.json\", \"r\") as f:\n",
    "    index_to_chunk = json.load(f)\n",
    "\n",
    "# Load Sentence Transformer for retrieval\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Read questions from questions.txt\n",
    "with open(\"data/train/questions.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    questions = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "# Dictionary to store answers\n",
    "system_output = {}\n",
    "\n",
    "# Process each question\n",
    "for idx, question in enumerate(questions, start=1):\n",
    "    # Encode question\n",
    "    query_embedding = sentence_model.encode([question])\n",
    "\n",
    "    # Compute cosine similarity for top-k retrieval\n",
    "    cosine_similarities = np.dot(embeddings, query_embedding.T).flatten()\n",
    "    top_k_indices = np.argsort(cosine_similarities)[-5:]  # Retrieve top 3 chunks\n",
    "\n",
    "    # Combine retrieved chunks\n",
    "    retrieved_chunks = \" \".join([index_to_chunk[str(i)] for i in top_k_indices])\n",
    "\n",
    "    # **Truncate to fit 512 tokens**\n",
    "    max_context_tokens = 450\n",
    "    context_tokens = tokenizer.tokenize(retrieved_chunks)[:max_context_tokens]\n",
    "    truncated_context = tokenizer.convert_tokens_to_string(context_tokens)\n",
    "\n",
    "    # Construct prompt\n",
    "    prompt = f\"question: {question} context: {truncated_context}\"\n",
    "\n",
    "    # Tokenize and generate an answer\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "    output_ids = model.generate(\n",
    "        input_ids, \n",
    "        max_length=100,  \n",
    "        num_beams=7,  # More diverse answers\n",
    "        early_stopping=True\n",
    "    )\n",
    "    answer = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # Store the answer\n",
    "    system_output[str(idx)] = answer\n",
    "\n",
    "    print(f\"Q: {question}\")\n",
    "    print(f\"A: {answer}\\n\")\n",
    "\n",
    "# Save all answers to system_output.json\n",
    "with open(\"system_output.json\", \"w\") as f:\n",
    "    json.dump(system_output, f, indent=4)\n",
    "\n",
    "print(\"All answers saved in system_output.json.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Current Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk -q\n",
    "%pip install rouge -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Average BLEU Score (with smoothing): 0.0110\n",
      "🔹 Average ROUGE Score: 0.1085\n",
      "🔹 Exact Match Accuracy: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge import Rouge\n",
    "import json\n",
    "\n",
    "# Load system-generated answers\n",
    "with open(\"system_output.json\", \"r\") as f:\n",
    "    system_output = json.load(f)\n",
    "\n",
    "# Load reference answers\n",
    "with open(\"data/train/reference_answers.json\", \"r\") as f:\n",
    "    reference_answers = json.load(f)\n",
    "\n",
    "# Initialize metrics\n",
    "rouge = Rouge()\n",
    "total_bleu = 0\n",
    "total_rouge = 0\n",
    "exact_match = 0\n",
    "num_questions = len(reference_answers)\n",
    "\n",
    "# Smoothing function for BLEU\n",
    "smooth_fn = SmoothingFunction().method1  # Prevents BLEU from being 0 due to missing n-grams\n",
    "\n",
    "# Compare each generated answer with the reference\n",
    "for idx, ref_list in reference_answers.items():\n",
    "    generated_answer = system_output.get(idx, \"\").strip()\n",
    "\n",
    "    # Extract the reference answer\n",
    "    ref_answer = ref_list[0].strip()\n",
    "\n",
    "    # Compute BLEU score with smoothing\n",
    "    bleu_score = sentence_bleu([ref_answer.split()], generated_answer.split(), smoothing_function=smooth_fn)\n",
    "    total_bleu += bleu_score\n",
    "\n",
    "    # Compute ROUGE score\n",
    "    rouge_score = rouge.get_scores(generated_answer, ref_answer)[0][\"rouge-l\"][\"f\"]\n",
    "    total_rouge += rouge_score\n",
    "\n",
    "    # Compute Exact Match\n",
    "    if generated_answer.lower() == ref_answer.lower():\n",
    "        exact_match += 1\n",
    "\n",
    "# Compute final averages\n",
    "avg_bleu = total_bleu / num_questions\n",
    "avg_rouge = total_rouge / num_questions\n",
    "exact_match_score = exact_match / num_questions\n",
    "\n",
    "# Print results\n",
    "print(f\"🔹 Average BLEU Score (with smoothing): {avg_bleu:.4f}\")\n",
    "print(f\"🔹 Average ROUGE Score: {avg_rouge:.4f}\")\n",
    "print(f\"🔹 Exact Match Accuracy: {exact_match_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/yl/4xc46_3j4b7g9f0y2dh5kxv00000gn/T/ipykernel_1747/1259234130.py:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You have set `args.eval_strategy` to IntervalStrategy.EPOCH but you didn't pass an `eval_dataset` to `Trainer`. Either set `args.eval_strategy` to `no` or pass an `eval_dataset`. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 75\u001b[0m\n\u001b[1;32m     59\u001b[0m training_args \u001b[38;5;241m=\u001b[39m Seq2SeqTrainingArguments(\n\u001b[1;32m     60\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./flan-t5-finetuned\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     61\u001b[0m     evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m     fp16\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available(),\n\u001b[1;32m     72\u001b[0m )\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Trainer\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mSeq2SeqTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Fine-tune the model\u001b[39;00m\n\u001b[1;32m     83\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/trainer_seq2seq.py:73\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;129m@deprecate_kwarg\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessing_class\u001b[39m\u001b[38;5;124m\"\u001b[39m, version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m, raise_if_both_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m     preprocess_logits_for_metrics: Optional[Callable[[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor], torch\u001b[38;5;241m.\u001b[39mTensor]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     72\u001b[0m ):\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_collator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprocessing_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessing_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompute_loss_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_loss_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreprocess_logits_for_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocess_logits_for_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;66;03m# Override self.model.generation_config if a GenerationConfig is specified in args.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# Priority: args.generation_config > model.generation_config > default GenerationConfig.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgeneration_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/trainer.py:443\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    438\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen using `batch_eval_metrics`, your `compute_metrics` function must take a `compute_result`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    439\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m boolean argument which will be triggered after the last batch of the eval set to signal that the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    440\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m summary statistics should be returned by the function.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    441\u001b[0m         )\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39meval_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m args\u001b[38;5;241m.\u001b[39meval_strategy \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m eval_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have set `args.eval_strategy` to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39meval_strategy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but you didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pass an `eval_dataset` to `Trainer`. Either set `args.eval_strategy` to `no` or pass an `eval_dataset`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m     )\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39msave_strategy \u001b[38;5;241m==\u001b[39m SaveStrategy\u001b[38;5;241m.\u001b[39mBEST \u001b[38;5;129;01mor\u001b[39;00m args\u001b[38;5;241m.\u001b[39mload_best_model_at_end:\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mmetric_for_best_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: You have set `args.eval_strategy` to IntervalStrategy.EPOCH but you didn't pass an `eval_dataset` to `Trainer`. Either set `args.eval_strategy` to `no` or pass an `eval_dataset`. "
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, T5Tokenizer, T5ForConditionalGeneration\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "# Load pre-trained model\n",
    "model_name = \"google/flan-t5-large\"  \n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Load questions & reference answers\n",
    "with open(\"data/train/questions.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    questions = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "with open(\"data/train/reference_answers.json\", \"r\") as f:\n",
    "    reference_answers = json.load(f)\n",
    "\n",
    "# Convert data to a format suitable for training\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, tokenizer, questions, answers, max_length=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.questions = questions\n",
    "        self.answers = answers\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        question = self.questions[idx]\n",
    "        answer = reference_answers[str(idx + 1)][0]  # Extract reference answer\n",
    "\n",
    "        # Encode question and answer\n",
    "        inputs = tokenizer(\n",
    "            f\"question: {question}\", \n",
    "            padding=\"max_length\", \n",
    "            truncation=True, \n",
    "            max_length=self.max_length, \n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        targets = tokenizer(\n",
    "            answer, \n",
    "            padding=\"max_length\", \n",
    "            truncation=True, \n",
    "            max_length=100, \n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": targets[\"input_ids\"].squeeze(),\n",
    "        }\n",
    "\n",
    "# Create dataset\n",
    "dataset = QADataset(tokenizer, questions, reference_answers)\n",
    "\n",
    "# Training Arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./flan-t5-finetuned\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=5,  # Increase to 5 epochs for better learning\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    fp16=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n",
    "\n",
    "# Save model\n",
    "model.save_pretrained(\"./flan-t5-finetuned\")\n",
    "tokenizer.save_pretrained(\"./flan-t5-finetuned\")\n",
    "print(\"Fine-tuning completed. Model saved!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a more powerful T5 model\n",
    "model_name = \"./flan-t5-finetuned\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Load embeddings and index-to-chunk mapping\n",
    "embeddings = np.load('pittsburgh_embeddings.npy')\n",
    "with open(\"index_to_chunk.json\", \"r\") as f:\n",
    "    index_to_chunk = json.load(f)\n",
    "\n",
    "# Load Sentence Transformer for retrieval\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Read questions from questions.txt\n",
    "with open(\"data/train/questions.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    questions = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "# Dictionary to store answers\n",
    "system_output = {}\n",
    "\n",
    "# Process each question\n",
    "for idx, question in enumerate(questions, start=1):\n",
    "    # Encode question\n",
    "    query_embedding = sentence_model.encode([question])\n",
    "\n",
    "    # Compute cosine similarity for top-k retrieval\n",
    "    cosine_similarities = np.dot(embeddings, query_embedding.T).flatten()\n",
    "    top_k_indices = np.argsort(cosine_similarities)[-5:]  # Retrieve top 3 chunks\n",
    "\n",
    "    # Combine retrieved chunks\n",
    "    retrieved_chunks = \" \".join([index_to_chunk[str(i)] for i in top_k_indices])\n",
    "\n",
    "    # **Truncate to fit 512 tokens**\n",
    "    max_context_tokens = 450\n",
    "    context_tokens = tokenizer.tokenize(retrieved_chunks)[:max_context_tokens]\n",
    "    truncated_context = tokenizer.convert_tokens_to_string(context_tokens)\n",
    "\n",
    "    # Construct prompt\n",
    "    prompt = f\"question: {question} context: {truncated_context}\"\n",
    "\n",
    "    # Tokenize and generate an answer\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "    output_ids = model.generate(\n",
    "        input_ids, \n",
    "        max_length=100,  \n",
    "        num_beams=7,  # More diverse answers\n",
    "        early_stopping=True\n",
    "    )\n",
    "    answer = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # Store the answer\n",
    "    system_output[str(idx)] = answer\n",
    "\n",
    "    print(f\"Q: {question}\")\n",
    "    print(f\"A: {answer}\\n\")\n",
    "\n",
    "# Save all answers to system_output.json\n",
    "with open(\"system_output.json\", \"w\") as f:\n",
    "    json.dump(system_output, f, indent=4)\n",
    "\n",
    "print(\"All answers saved in system_output.json.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (4.49.0)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0.tar.gz (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jaipdalvi/Library/Python/3.13/lib/python/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->transformers) (2025.1.31)\n",
      "Building wheels for collected packages: sentencepiece\n",
      "  Building wheel for sentencepiece (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for sentencepiece \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[108 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/yl/4xc46_3j4b7g9f0y2dh5kxv00000gn/T/pip-build-env-kzfijt5c/overlay/lib/python3.13/site-packages/setuptools/_distutils/dist.py:270: UserWarning: Unknown distribution option: 'test_suite'\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(msg)\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.13-universal2-cpython-313/sentencepiece\n",
      "  \u001b[31m   \u001b[0m copying src/sentencepiece/__init__.py -> build/lib.macosx-10.13-universal2-cpython-313/sentencepiece\n",
      "  \u001b[31m   \u001b[0m copying src/sentencepiece/_version.py -> build/lib.macosx-10.13-universal2-cpython-313/sentencepiece\n",
      "  \u001b[31m   \u001b[0m copying src/sentencepiece/sentencepiece_model_pb2.py -> build/lib.macosx-10.13-universal2-cpython-313/sentencepiece\n",
      "  \u001b[31m   \u001b[0m copying src/sentencepiece/sentencepiece_pb2.py -> build/lib.macosx-10.13-universal2-cpython-313/sentencepiece\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m /bin/sh: pkg-config: command not found\n",
      "  \u001b[31m   \u001b[0m ./build_bundled.sh: line 21: cmake: command not found\n",
      "  \u001b[31m   \u001b[0m ./build_bundled.sh: line 22: nproc: command not found\n",
      "  \u001b[31m   \u001b[0m ./build_bundled.sh: line 22: cmake: command not found\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\"\u001b[0m, line \u001b[35m389\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\"\u001b[0m, line \u001b[35m373\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     json_out[\"return_val\"] = \u001b[31mhook\u001b[0m\u001b[1;31m(**hook_input[\"kwargs\"])\u001b[0m\n",
      "  \u001b[31m   \u001b[0m                              \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\"\u001b[0m, line \u001b[35m280\u001b[0m, in \u001b[35mbuild_wheel\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     return \u001b[31m_build_backend().build_wheel\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "  \u001b[31m   \u001b[0m            \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m         \u001b[1;31mwheel_directory, config_settings, metadata_directory\u001b[0m\n",
      "  \u001b[31m   \u001b[0m         \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[1;31m)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[1;31m^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/yl/4xc46_3j4b7g9f0y2dh5kxv00000gn/T/pip-build-env-kzfijt5c/overlay/lib/python3.13/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m438\u001b[0m, in \u001b[35mbuild_wheel\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     return _build(['bdist_wheel', '--dist-info-dir', str(metadata_directory)])\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/yl/4xc46_3j4b7g9f0y2dh5kxv00000gn/T/pip-build-env-kzfijt5c/overlay/lib/python3.13/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m426\u001b[0m, in \u001b[35m_build\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     return \u001b[31mself._build_with_temp_dir\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "  \u001b[31m   \u001b[0m            \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m         \u001b[1;31mcmd,\u001b[0m\n",
      "  \u001b[31m   \u001b[0m         \u001b[1;31m^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     ...<3 lines>...\n",
      "  \u001b[31m   \u001b[0m         \u001b[1;31mself._arbitrary_args(config_settings),\u001b[0m\n",
      "  \u001b[31m   \u001b[0m         \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[1;31m)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[1;31m^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/yl/4xc46_3j4b7g9f0y2dh5kxv00000gn/T/pip-build-env-kzfijt5c/overlay/lib/python3.13/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m407\u001b[0m, in \u001b[35m_build_with_temp_dir\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself.run_setup\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/yl/4xc46_3j4b7g9f0y2dh5kxv00000gn/T/pip-build-env-kzfijt5c/overlay/lib/python3.13/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m522\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31msuper().run_setup\u001b[0m\u001b[1;31m(setup_script=setup_script)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/yl/4xc46_3j4b7g9f0y2dh5kxv00000gn/T/pip-build-env-kzfijt5c/overlay/lib/python3.13/site-packages/setuptools/build_meta.py\"\u001b[0m, line \u001b[35m320\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mexec\u001b[0m\u001b[1;31m(code, locals())\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m169\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/yl/4xc46_3j4b7g9f0y2dh5kxv00000gn/T/pip-build-env-kzfijt5c/overlay/lib/python3.13/site-packages/setuptools/__init__.py\"\u001b[0m, line \u001b[35m117\u001b[0m, in \u001b[35msetup\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     return \u001b[31mdistutils.core.setup\u001b[0m\u001b[1;31m(**attrs)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m            \u001b[31m~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/yl/4xc46_3j4b7g9f0y2dh5kxv00000gn/T/pip-build-env-kzfijt5c/overlay/lib/python3.13/site-packages/setuptools/_distutils/core.py\"\u001b[0m, line \u001b[35m186\u001b[0m, in \u001b[35msetup\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/yl/4xc46_3j4b7g9f0y2dh5kxv00000gn/T/pip-build-env-kzfijt5c/overlay/lib/python3.13/site-packages/setuptools/_distutils/core.py\"\u001b[0m, line \u001b[35m202\u001b[0m, in \u001b[35mrun_commands\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mdist.run_commands\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/yl/4xc46_3j4b7g9f0y2dh5kxv00000gn/T/pip-build-env-kzfijt5c/overlay/lib/python3.13/site-packages/setuptools/_distutils/dist.py\"\u001b[0m, line \u001b[35m983\u001b[0m, in \u001b[35mrun_commands\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself.run_command\u001b[0m\u001b[1;31m(cmd)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/yl/4xc46_3j4b7g9f0y2dh5kxv00000gn/T/pip-build-env-kzfijt5c/overlay/lib/python3.13/site-packages/setuptools/dist.py\"\u001b[0m, line \u001b[35m999\u001b[0m, in \u001b[35mrun_command\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31msuper().run_command\u001b[0m\u001b[1;31m(command)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/yl/4xc46_3j4b7g9f0y2dh5kxv00000gn/T/pip-build-env-kzfijt5c/overlay/lib/python3.13/site-packages/setuptools/_distutils/dist.py\"\u001b[0m, line \u001b[35m1002\u001b[0m, in \u001b[35mrun_command\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mcmd_obj.run\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/yl/4xc46_3j4b7g9f0y2dh5kxv00000gn/T/pip-build-env-kzfijt5c/overlay/lib/python3.13/site-packages/setuptools/command/bdist_wheel.py\"\u001b[0m, line \u001b[35m369\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself.run_command\u001b[0m\u001b[1;31m(\"build\")\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/yl/4xc46_3j4b7g9f0y2dh5kxv00000gn/T/pip-build-env-kzfijt5c/overlay/lib/python3.13/site-packages/setuptools/_distutils/cmd.py\"\u001b[0m, line \u001b[35m339\u001b[0m, in \u001b[35mrun_command\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself.distribution.run_command\u001b[0m\u001b[1;31m(command)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/yl/4xc46_3j4b7g9f0y2dh5kxv00000gn/T/pip-build-env-kzfijt5c/overlay/lib/python3.13/site-packages/setuptools/dist.py\"\u001b[0m, line \u001b[35m999\u001b[0m, in \u001b[35mrun_command\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31msuper().run_command\u001b[0m\u001b[1;31m(command)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/yl/4xc46_3j4b7g9f0y2dh5kxv00000gn/T/pip-build-env-kzfijt5c/overlay/lib/python3.13/site-packages/setuptools/_distutils/dist.py\"\u001b[0m, line \u001b[35m1002\u001b[0m, in \u001b[35mrun_command\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mcmd_obj.run\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/yl/4xc46_3j4b7g9f0y2dh5kxv00000gn/T/pip-build-env-kzfijt5c/overlay/lib/python3.13/site-packages/setuptools/_distutils/command/build.py\"\u001b[0m, line \u001b[35m136\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself.run_command\u001b[0m\u001b[1;31m(cmd_name)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/yl/4xc46_3j4b7g9f0y2dh5kxv00000gn/T/pip-build-env-kzfijt5c/overlay/lib/python3.13/site-packages/setuptools/_distutils/cmd.py\"\u001b[0m, line \u001b[35m339\u001b[0m, in \u001b[35mrun_command\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself.distribution.run_command\u001b[0m\u001b[1;31m(command)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/yl/4xc46_3j4b7g9f0y2dh5kxv00000gn/T/pip-build-env-kzfijt5c/overlay/lib/python3.13/site-packages/setuptools/dist.py\"\u001b[0m, line \u001b[35m999\u001b[0m, in \u001b[35mrun_command\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31msuper().run_command\u001b[0m\u001b[1;31m(command)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/yl/4xc46_3j4b7g9f0y2dh5kxv00000gn/T/pip-build-env-kzfijt5c/overlay/lib/python3.13/site-packages/setuptools/_distutils/dist.py\"\u001b[0m, line \u001b[35m1002\u001b[0m, in \u001b[35mrun_command\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mcmd_obj.run\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/yl/4xc46_3j4b7g9f0y2dh5kxv00000gn/T/pip-build-env-kzfijt5c/overlay/lib/python3.13/site-packages/setuptools/command/build_ext.py\"\u001b[0m, line \u001b[35m99\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m_build_ext.run\u001b[0m\u001b[1;31m(self)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/yl/4xc46_3j4b7g9f0y2dh5kxv00000gn/T/pip-build-env-kzfijt5c/overlay/lib/python3.13/site-packages/setuptools/_distutils/command/build_ext.py\"\u001b[0m, line \u001b[35m365\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself.build_extensions\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/yl/4xc46_3j4b7g9f0y2dh5kxv00000gn/T/pip-build-env-kzfijt5c/overlay/lib/python3.13/site-packages/setuptools/_distutils/command/build_ext.py\"\u001b[0m, line \u001b[35m481\u001b[0m, in \u001b[35mbuild_extensions\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself._build_extensions_serial\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/yl/4xc46_3j4b7g9f0y2dh5kxv00000gn/T/pip-build-env-kzfijt5c/overlay/lib/python3.13/site-packages/setuptools/_distutils/command/build_ext.py\"\u001b[0m, line \u001b[35m507\u001b[0m, in \u001b[35m_build_extensions_serial\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself.build_extension\u001b[0m\u001b[1;31m(ext)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m87\u001b[0m, in \u001b[35mbuild_extension\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/subprocess.py\"\u001b[0m, line \u001b[35m419\u001b[0m, in \u001b[35mcheck_call\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     raise CalledProcessError(retcode, cmd)\n",
      "  \u001b[31m   \u001b[0m \u001b[1;35msubprocess.CalledProcessError\u001b[0m: \u001b[35mCommand '['./build_bundled.sh', '0.2.0']' returned non-zero exit status 127.\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for sentencepiece\u001b[0m\u001b[31m\n",
      "\u001b[0mFailed to build sentencepiece\n",
      "\u001b[31mERROR: Failed to build installable wheels for some pyproject.toml based projects (sentencepiece)\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_wikipedia(url=\"https://en.wikipedia.org/wiki/Pittsburgh\"):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Failed to retrieve the page.\")\n",
    "        return \"\"\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    content_div = soup.find(\"div\", id=\"mw-content-text\")\n",
    "    if not content_div:\n",
    "        return \"\"\n",
    "    paragraphs = content_div.find_all(\"p\")\n",
    "    text = \"\\n\".join([p.get_text().strip() for p in paragraphs if p.get_text().strip() != \"\"])\n",
    "    return text\n",
    "\n",
    "def chunk_text(text, chunk_size=250):  # using a smaller chunk size\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size):\n",
    "        chunk = \" \".join(words[i:i + chunk_size])\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "\n",
    "# Scrape Pittsburgh Wikipedia page and chunk the text\n",
    "full_text = scrape_wikipedia(\"https://en.wikipedia.org/wiki/Pittsburgh\")\n",
    "chunks = chunk_text(full_text, chunk_size=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Converting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast convertors: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/convert_slow_tokenizer.py:1585\u001b[0m, in \u001b[0;36mTikTokenConverter.extract_vocab_merges_from_model\u001b[0;34m(self, tiktoken_url)\u001b[0m\n\u001b[1;32m   1584\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1585\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtiktoken\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_tiktoken_bpe\n\u001b[1;32m   1586\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tiktoken'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/convert_slow_tokenizer.py:1725\u001b[0m, in \u001b[0;36mconvert_slow_tokenizer\u001b[0;34m(transformer_tokenizer, from_tiktoken)\u001b[0m\n\u001b[1;32m   1721\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting from Tiktoken\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1722\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTikTokenConverter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1723\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformer_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1724\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformer_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madditional_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 1725\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/convert_slow_tokenizer.py:1622\u001b[0m, in \u001b[0;36mTikTokenConverter.converted\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1621\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconverted\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tokenizer:\n\u001b[0;32m-> 1622\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1623\u001b[0m     tokenizer\u001b[38;5;241m.\u001b[39mpre_tokenizer \u001b[38;5;241m=\u001b[39m pre_tokenizers\u001b[38;5;241m.\u001b[39mSequence(\n\u001b[1;32m   1624\u001b[0m         [\n\u001b[1;32m   1625\u001b[0m             pre_tokenizers\u001b[38;5;241m.\u001b[39mSplit(Regex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpattern), behavior\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124misolated\u001b[39m\u001b[38;5;124m\"\u001b[39m, invert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1626\u001b[0m             pre_tokenizers\u001b[38;5;241m.\u001b[39mByteLevel(add_prefix_space\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space, use_regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1627\u001b[0m         ]\n\u001b[1;32m   1628\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/convert_slow_tokenizer.py:1615\u001b[0m, in \u001b[0;36mTikTokenConverter.tokenizer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtokenizer\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1615\u001b[0m     vocab_scores, merges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_vocab_merges_from_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1616\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m Tokenizer(BPE(vocab_scores, merges, fuse_unk\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/convert_slow_tokenizer.py:1587\u001b[0m, in \u001b[0;36mTikTokenConverter.extract_vocab_merges_from_model\u001b[0;34m(self, tiktoken_url)\u001b[0m\n\u001b[1;32m   1586\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m-> 1587\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1588\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tiktoken` is required to read a `tiktoken` file. Install it with \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tiktoken`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1589\u001b[0m     )\n\u001b[1;32m   1591\u001b[0m bpe_ranks \u001b[38;5;241m=\u001b[39m load_tiktoken_bpe(tiktoken_url)\n",
      "\u001b[0;31mValueError\u001b[0m: `tiktoken` is required to read a `tiktoken` file. Install it with `pip install tiktoken`.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize the question generation pipeline\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m qg_pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext2text-generation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalhalla/t5-small-qg-prepend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Initialize the question answering pipeline\u001b[39;00m\n\u001b[1;32m      7\u001b[0m qa_pipeline \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion-answering\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepset/roberta-base-squad2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/pipelines/__init__.py:1047\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m   1044\u001b[0m             tokenizer_kwargs \u001b[38;5;241m=\u001b[39m model_kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m   1045\u001b[0m             tokenizer_kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1047\u001b[0m         tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtokenizer_identifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_fast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_from_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtokenizer_kwargs\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_image_processor:\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;66;03m# Try to infer image processor from model or config name (if provided as str)\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m image_processor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py:963\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    960\u001b[0m tokenizer_class_py, tokenizer_class_fast \u001b[38;5;241m=\u001b[39m TOKENIZER_MAPPING[\u001b[38;5;28mtype\u001b[39m(config)]\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_fast \u001b[38;5;129;01mand\u001b[39;00m (use_fast \u001b[38;5;129;01mor\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer_class_fast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/tokenization_utils_base.py:2052\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2049\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2050\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_vocab_files[file_id]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2052\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresolved_vocab_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2060\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2061\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_is_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2063\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2064\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/tokenization_utils_base.py:2292\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2290\u001b[0m \u001b[38;5;66;03m# Instantiate the tokenizer.\u001b[39;00m\n\u001b[1;32m   2291\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2292\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2293\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m import_protobuf_decode_error():\n\u001b[1;32m   2294\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   2295\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to load tokenizer model from SPM, loading from TikToken will be attempted instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2296\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Google protobuf error: Tried to load SPM model with non-SPM vocab file).\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2297\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/models/t5/tokenization_t5_fast.py:119\u001b[0m, in \u001b[0;36mT5TokenizerFast.__init__\u001b[0;34m(self, vocab_file, tokenizer_file, eos_token, unk_token, pad_token, extra_ids, additional_special_tokens, add_prefix_space, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning_once(\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_slow\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meos_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43munk_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munk_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_prefix_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_prefix_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_file \u001b[38;5;241m=\u001b[39m vocab_file\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extra_ids \u001b[38;5;241m=\u001b[39m extra_ids\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/tokenization_utils_fast.py:139\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madditional_special_tokens \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madditional_special_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n\u001b[0;32m--> 139\u001b[0m     fast_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_slow_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_tiktoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     slow_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/convert_slow_tokenizer.py:1727\u001b[0m, in \u001b[0;36mconvert_slow_tokenizer\u001b[0;34m(transformer_tokenizer, from_tiktoken)\u001b[0m\n\u001b[1;32m   1722\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TikTokenConverter(\n\u001b[1;32m   1723\u001b[0m         vocab_file\u001b[38;5;241m=\u001b[39mtransformer_tokenizer\u001b[38;5;241m.\u001b[39mvocab_file,\n\u001b[1;32m   1724\u001b[0m         additional_special_tokens\u001b[38;5;241m=\u001b[39mtransformer_tokenizer\u001b[38;5;241m.\u001b[39madditional_special_tokens,\n\u001b[1;32m   1725\u001b[0m     )\u001b[38;5;241m.\u001b[39mconverted()\n\u001b[1;32m   1726\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m-> 1727\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1728\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1729\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith a SentencePiece tokenizer.model file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1730\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently available slow->fast convertors: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(SLOW_TO_FAST_CONVERTERS\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1731\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Converting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast convertors: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the question generation pipeline\n",
    "qg_pipeline = pipeline(\"text2text-generation\", model=\"valhalla/t5-small-qg-prepend\")\n",
    "\n",
    "# Initialize the question answering pipeline\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
    "\n",
    "all_qa_pairs = []\n",
    "for i, chunk in enumerate(chunks):\n",
    "    try:\n",
    "        # Generate a question from the chunk.\n",
    "        prompt = \"generate question: \" + chunk\n",
    "        qg_outputs = qg_pipeline(prompt)\n",
    "        for out in qg_outputs:\n",
    "            question = out['generated_text'].strip()\n",
    "            \n",
    "            # Now extract an answer from the same chunk using the generated question.\n",
    "            qa_result = qa_pipeline(question=question, context=chunk)\n",
    "            answer = qa_result.get('answer', \"No answer found\")\n",
    "            \n",
    "            qa_pair = {\n",
    "                \"question\": question,\n",
    "                \"answer\": answer,\n",
    "                \"chunk_index\": i\n",
    "            }\n",
    "            all_qa_pairs.append(qa_pair)\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating Q&A for chunk {i}: {e}\")\n",
    "\n",
    "print(f\"Total Q&A pairs generated: {len(all_qa_pairs)}\")\n",
    "\n",
    "# Show a few examples\n",
    "for idx, qa in enumerate(all_qa_pairs[:100], start=1):\n",
    "    print(f\"Q{idx}: {qa['question']}\\nA{idx}: {qa['answer']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Q&A pairs generated: 50\n",
      "Q1: What is the name of the city that is located in Pennsylvania?\n",
      "A1: Philadelphia\n",
      "\n",
      "Q2: What did the city focus on?\n",
      "A2: healthcare, education, and technology industries\n",
      "\n",
      "Q3: What is the name of the borough of Pittsburgh?\n",
      "A3: Pittsburgh for ever\n",
      "\n",
      "Q4: What did the British build Fort Prince George?\n",
      "A4: hastily\n",
      "\n",
      "Q5: What direction did Pittsburgh's first civilian local government go?\n",
      "A5: westward\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from transformers import pipeline\n",
    "\n",
    "def scrape_wikipedia(url=\"https://en.wikipedia.org/wiki/Pittsburgh\"):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Failed to retrieve the page.\")\n",
    "        return \"\"\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    content_div = soup.find(\"div\", id=\"mw-content-text\")\n",
    "    if not content_div:\n",
    "        return \"\"\n",
    "    paragraphs = content_div.find_all(\"p\")\n",
    "    text = \"\\n\".join([p.get_text().strip() for p in paragraphs if p.get_text().strip() != \"\"])\n",
    "    return text\n",
    "\n",
    "def chunk_text(text, chunk_size=250):  # using a smaller chunk size\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size):\n",
    "        chunk = \" \".join(words[i:i + chunk_size])\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "# Scrape Pittsburgh Wikipedia page and chunk the text\n",
    "full_text = scrape_wikipedia(\"https://en.wikipedia.org/wiki/Pittsburgh\")\n",
    "chunks = chunk_text(full_text, chunk_size=250)\n",
    "\n",
    "# Initialize the question generation pipeline (using text2text-generation with a prompt)\n",
    "qg_pipeline = pipeline(\"text2text-generation\", model=\"valhalla/t5-small-qg-prepend\")\n",
    "\n",
    "# Initialize the question answering pipeline\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
    "\n",
    "all_qa_pairs = []\n",
    "for i, chunk in enumerate(chunks):\n",
    "    try:\n",
    "        # Generate a question from the chunk.\n",
    "        prompt = \"generate question: \" + chunk\n",
    "        qg_outputs = qg_pipeline(prompt)\n",
    "        for out in qg_outputs:\n",
    "            question = out['generated_text'].strip()\n",
    "            \n",
    "            # Now extract an answer from the same chunk using the generated question.\n",
    "            qa_result = qa_pipeline(question=question, context=chunk)\n",
    "            answer = qa_result.get('answer', \"No answer found\")\n",
    "            \n",
    "            qa_pair = {\n",
    "                \"question\": question,\n",
    "                \"answer\": answer,\n",
    "                \"chunk_index\": i\n",
    "            }\n",
    "            all_qa_pairs.append(qa_pair)\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating Q&A for chunk {i}: {e}\")\n",
    "\n",
    "print(f\"Total Q&A pairs generated: {len(all_qa_pairs)}\")\n",
    "\n",
    "# Show a few examples\n",
    "for idx, qa in enumerate(all_qa_pairs[:5], start=1):\n",
    "    print(f\"Q{idx}: {qa['question']}\\nA{idx}: {qa['answer']}\\n\")\n",
    "\n",
    "# ----- Now write out the files -----\n",
    "\n",
    "# Write questions.txt (one question per line)\n",
    "with open(\"questions.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for qa in all_qa_pairs:\n",
    "        f.write(qa[\"question\"] + \"\\n\")\n",
    "\n",
    "# Write system_output.json: mapping from question number to the generated answer\n",
    "system_output = {str(idx + 1): qa[\"answer\"] for idx, qa in enumerate(all_qa_pairs)}\n",
    "with open(\"system_output.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(system_output, f, indent=2)\n",
    "\n",
    "# Write reference_answers.json: here we use the same answers as placeholders.\n",
    "# In practice, you would update this file with manually verified or annotated answers.\n",
    "reference_answers = {str(idx + 1): qa[\"answer\"] for idx, qa in enumerate(all_qa_pairs)}\n",
    "with open(\"reference_answers.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(reference_answers, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735ff40338544949aaf4ff3d1dd0c64e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e260489e8d4646819b7dc1580c151974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9255ff2b4ad041c194b96d3fcc2fbd80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff30fb33dd4e4a9dadbc2e9a4dfc331a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e74d8733774129b2714e1ba9775e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe8b6dbf97146bfab8ac209a55b777d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c4a31d17504c78b1fdb730d8987fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Q&A pairs generated: 50\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# For example, using a text generation model\n",
    "llm_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
    "\n",
    "# A function that generates an answer using the LLM\n",
    "def generate_answer(question, context):\n",
    "    prompt = f\"Context: {context}\\nQuestion: {question}\\nAnswer:\"\n",
    "    output = llm_pipeline(prompt, max_length=100, truncation=True)\n",
    "    return output[0]['generated_text'].strip()\n",
    "\n",
    "# Now, assuming you already generated your questions (e.g., using the qg_pipeline), you can generate answers:\n",
    "all_qa_pairs = []\n",
    "for i, chunk in enumerate(chunks):\n",
    "    try:\n",
    "        # Generate a question from the chunk.\n",
    "        prompt = \"generate question: \" + chunk\n",
    "        qg_outputs = qg_pipeline(prompt)\n",
    "        for out in qg_outputs:\n",
    "            question = out['generated_text'].strip()\n",
    "            \n",
    "            # Now generate an answer using the LLM and the chunk as context.\n",
    "            answer = generate_answer(question, chunk)\n",
    "            \n",
    "            qa_pair = {\n",
    "                \"question\": question,\n",
    "                \"answer\": answer,\n",
    "                \"chunk_index\": i\n",
    "            }\n",
    "            all_qa_pairs.append(qa_pair)\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating Q&A for chunk {i}: {e}\")\n",
    "\n",
    "print(f\"Total Q&A pairs generated: {len(all_qa_pairs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files 'questions.txt' and 'reference_answers.json' have been created successfully.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# List of questions from the Pittsburgh Wikipedia page\n",
    "questions = [\n",
    "    \"Where is Pittsburgh located geographically?\",\n",
    "    \"What are the major rivers that converge in Pittsburgh?\",\n",
    "    \"Why is Pittsburgh known as the 'Steel City'?\",\n",
    "    \"What is the historical significance of Pittsburgh in the industrial revolution?\",\n",
    "    \"Who were the early settlers of Pittsburgh?\",\n",
    "    \"What are the major educational institutions in Pittsburgh?\",\n",
    "    \"How has Pittsburgh's economy transitioned from manufacturing to technology and healthcare?\",\n",
    "    \"What are the popular cultural and tourist attractions in Pittsburgh?\",\n",
    "    \"What are the major sports teams based in Pittsburgh?\",\n",
    "    \"How does Pittsburgh contribute to arts and theater?\"\n",
    "]\n",
    "\n",
    "# Corresponding answers (one or more per question)\n",
    "answers = {\n",
    "    \"1\": [\"Pittsburgh is located in western Pennsylvania, at the confluence of the Allegheny, Monongahela, and Ohio rivers.\"],\n",
    "    \"2\": [\"The Allegheny, Monongahela, and Ohio rivers converge in Pittsburgh.\"],\n",
    "    \"3\": [\"Pittsburgh is known as the 'Steel City' due to its historical role as a major steel manufacturing hub.\"],\n",
    "    \"4\": [\"Pittsburgh was a key industrial center during the industrial revolution, known for its steel production and manufacturing.\"],\n",
    "    \"5\": [\"The early settlers of Pittsburgh were Native Americans, followed by French and British colonists.\"],\n",
    "    \"6\": [\"Major educational institutions in Pittsburgh include the University of Pittsburgh and Carnegie Mellon University.\"],\n",
    "    \"7\": [\"Pittsburgh's economy has transitioned from manufacturing to focus on technology, healthcare, and education.\"],\n",
    "    \"8\": [\"Popular attractions in Pittsburgh include the Carnegie Museum of Art, Phipps Conservatory, and the Andy Warhol Museum.\"],\n",
    "    \"9\": [\"Major sports teams in Pittsburgh are the Pittsburgh Steelers (NFL), Pittsburgh Penguins (NHL), and Pittsburgh Pirates (MLB).\"],\n",
    "    \"10\": [\"Pittsburgh contributes to arts and theater through institutions like the Pittsburgh Symphony Orchestra and the Benedum Center.\"]\n",
    "}\n",
    "\n",
    "# Write questions to questions.txt\n",
    "with open('questions.txt', 'w') as file:\n",
    "    for question in questions:\n",
    "        file.write(question + '\\n')\n",
    "\n",
    "# Write reference answers to reference_answers.json\n",
    "with open('reference_answers.json', 'w') as file:\n",
    "    json.dump(answers, file, indent=4)\n",
    "\n",
    "print(\"Files 'questions.txt' and 'reference_answers.json' have been created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
